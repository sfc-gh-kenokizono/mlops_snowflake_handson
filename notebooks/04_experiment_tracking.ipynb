{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "8d68ef96",
      "metadata": {},
      "source": [
        "# Section 4: Experiment Trackingï¼ˆå®Ÿé¨“ç®¡ç†ï¼‰\n",
        "\n",
        "## ğŸ¯ ã“ã®ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã®ç›®æ¨™\n",
        "- **Snowflake ML Experiments** ã‚’ä½¿ã£ãŸå®Ÿé¨“ç®¡ç†ã‚’å­¦ã¶\n",
        "- è¤‡æ•°ãƒ¢ãƒ‡ãƒ«ã®æ¯”è¼ƒå®Ÿé¨“ã‚’è¡Œã†\n",
        "- ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒ»ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’è¨˜éŒ²ã—ã¦è¿½è·¡ã™ã‚‹\n",
        "\n",
        "## ğŸ“‹ Experiment Trackingã¨ã¯ï¼Ÿ\n",
        "æ©Ÿæ¢°å­¦ç¿’ã®å®Ÿé¨“ã‚’ä½“ç³»çš„ã«ç®¡ç†ã™ã‚‹ãŸã‚ã®æ©Ÿèƒ½ã§ã™ï¼š\n",
        "- ãƒ¢ãƒ‡ãƒ«ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã¨çµæœã‚’è¨˜éŒ²\n",
        "- è¤‡æ•°ã®å®Ÿé¨“ã‚’æ¯”è¼ƒ\n",
        "- å†ç¾æ€§ã®ã‚ã‚‹å®Ÿé¨“ç’°å¢ƒã‚’æ§‹ç¯‰\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ’¡ ãƒãƒ³ã‚ºã‚ªãƒ³ã§ã®ä½ç½®ã¥ã‘\n",
        "\n",
        "ã“ã®ãƒãƒ³ã‚ºã‚ªãƒ³ã§ã¯ã€**å„æ©Ÿèƒ½ã‚’ç‹¬ç«‹ã—ã¦å­¦ã¶**ã“ã¨ã‚’ç›®çš„ã¨ã—ã¦ã„ã¾ã™ã€‚\n",
        "\n",
        "| Section | å­¦ç¿’ç›®çš„ |\n",
        "|---------|----------|\n",
        "| 03 Model Training | ãƒã‚¤ãƒ‘ãƒ©**è‡ªå‹•æ¢ç´¢**ï¼ˆRandomizedSearchCVï¼‰ |\n",
        "| 04 Experiment Tracking | å®Ÿé¨“ã®**è¨˜éŒ²ãƒ»æ¯”è¼ƒ**æ©Ÿèƒ½ |\n",
        "\n",
        "ãã®ãŸã‚ã€03ã§è¦‹ã¤ã‘ãŸæœ€è‰¯ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã¨ã¯**åˆ¥ã«**ã€ç•°ãªã‚‹ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§å®Ÿé¨“ã‚’è¡Œã„ã€Experiment Trackingã®æ©Ÿèƒ½ã‚’ä½“é¨“ã—ã¾ã™ã€‚\n",
        "\n",
        "> ğŸ“ **å®Ÿé‹ç”¨ã§ã¯**: RandomizedSearchCVã®å„ã‚¤ãƒ†ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³çµæœã‚’Experiment Trackingã«è¨˜éŒ²ã—ã€ä¸€å…ƒç®¡ç†ã™ã‚‹ã“ã¨ãŒå¤šã„ã§ã™ã€‚\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "257b5f64",
      "metadata": {},
      "source": [
        "---\n",
        "## 4.1 ç’°å¢ƒè¨­å®š\n",
        "\n",
        "> ğŸ’¡ **ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã«ã¤ã„ã¦**: `environment.yml` ã«ã‚ˆã‚Šå¿…è¦ãªãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ï¼ˆsnowflake-ml-pythonç­‰ï¼‰ã¯è‡ªå‹•çš„ã«ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã¾ã™ã€‚\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "62e3d7ef",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Warningã‚’æŠ‘åˆ¶ï¼ˆãƒãƒ³ã‚ºã‚ªãƒ³å‘ã‘ï¼‰\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "from snowflake.snowpark.context import get_active_session\n",
        "from snowflake.snowpark import functions as F\n",
        "from snowflake.snowpark.types import *\n",
        "\n",
        "# MLé–¢é€£ï¼ˆsklearnç‰ˆã‚’ä½¿ç”¨ - ã‚³ãƒ³ãƒ†ãƒŠãƒ©ãƒ³ã‚¿ã‚¤ãƒ äº’æ›æ€§ã®ãŸã‚ï¼‰\n",
        "import xgboost as xgb\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import json\n",
        "\n",
        "# å¯è¦–åŒ–\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# SHAPï¼ˆãƒ¢ãƒ‡ãƒ«è§£é‡ˆæ€§ï¼‰\n",
        "import shap\n",
        "\n",
        "# Experiment Tracking\n",
        "from snowflake.ml.experiment import ExperimentTracking\n",
        "\n",
        "# ã‚»ãƒƒã‚·ãƒ§ãƒ³ã®å–å¾—\n",
        "session = get_active_session()\n",
        "\n",
        "# ç’°å¢ƒè¨­å®š\n",
        "session.use_database(\"MLOPS_HOL_DB\")\n",
        "session.use_schema(\"FEATURE_STORE\")\n",
        "session.use_warehouse(\"MLOPS_HOL_SQL_WH\")\n",
        "\n",
        "print(\"âœ… ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆå®Œäº†\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3414f11f",
      "metadata": {},
      "source": [
        "---\n",
        "## 4.2 Experiment Trackingã®åˆæœŸåŒ–\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0bdd1802",
      "metadata": {},
      "outputs": [],
      "source": [
        "# ExperimentTracking ã®ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹åŒ–\n",
        "exp = ExperimentTracking(session=session)\n",
        "\n",
        "# å®Ÿé¨“åã‚’è¨­å®š\n",
        "EXPERIMENT_NAME = \"CHURN_PREDICTION_EXPERIMENT\"\n",
        "exp.set_experiment(EXPERIMENT_NAME)\n",
        "\n",
        "print(f\"âœ… Experimentè¨­å®šå®Œäº†: {EXPERIMENT_NAME}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "67104cb6",
      "metadata": {},
      "source": [
        "---\n",
        "## 4.3 å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã®æº–å‚™\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aba30f07",
      "metadata": {},
      "outputs": [],
      "source": [
        "# å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’èª­ã¿è¾¼ã¿\n",
        "training_data = session.table(\"TRAINING_DATASET_V1\")\n",
        "\n",
        "# ç‰¹å¾´é‡ã¨ãƒ©ãƒ™ãƒ«ã®å®šç¾©\n",
        "FEATURE_COLS = [\n",
        "    \"DAYS_SINCE_LAST_ORDER\",\n",
        "    \"TOTAL_ORDER_COUNT\",\n",
        "    \"ORDER_COUNT_2024_H1\",\n",
        "    \"TOTAL_ORDER_AMOUNT\",\n",
        "    \"AVG_ORDER_AMOUNT\",\n",
        "    \"TOTAL_AMOUNT_2024_H1\",\n",
        "    \"RETURN_RATE\"\n",
        "]\n",
        "LABEL_COL = \"IS_CHURNED\"\n",
        "ID_COL = \"CUSTOMER_ID\"\n",
        "\n",
        "# ãƒ‡ãƒ¼ã‚¿ã®åˆ†å‰²\n",
        "model_data = training_data.select([ID_COL] + FEATURE_COLS + [LABEL_COL])\n",
        "train_sf, test_sf = model_data.random_split(weights=[0.8, 0.2], seed=42)\n",
        "\n",
        "# Pandas DataFrameã«å¤‰æ›ï¼ˆsklearnç”¨ï¼‰\n",
        "train_pd = train_sf.to_pandas()\n",
        "test_pd = test_sf.to_pandas()\n",
        "\n",
        "X_train = train_pd[FEATURE_COLS]\n",
        "y_train = train_pd[LABEL_COL]\n",
        "X_test = test_pd[FEATURE_COLS]\n",
        "y_test = test_pd[LABEL_COL]\n",
        "\n",
        "print(f\"è¨“ç·´ãƒ‡ãƒ¼ã‚¿: {len(train_pd):,} ä»¶\")\n",
        "print(f\"ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿: {len(test_pd):,} ä»¶\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f3eb49a2",
      "metadata": {},
      "source": [
        "---\n",
        "## 4.4 å®Ÿé¨“ã®å®Ÿè¡Œ\n",
        "\n",
        "è¤‡æ•°ã®ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§ãƒ¢ãƒ‡ãƒ«ã‚’è¨“ç·´ã—ã€çµæœã‚’è¨˜éŒ²ã—ã¾ã™ã€‚\n",
        "\n",
        "| Run | ç‰¹å¾´ | æœŸå¾… |\n",
        "|-----|------|------|\n",
        "| Baseline | ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ | åŸºæº–ãƒ¢ãƒ‡ãƒ« |\n",
        "| DeepTree | æ·±ã„æœ¨ (max_depth=10) | è¤‡é›‘ãªãƒ‘ã‚¿ãƒ¼ãƒ³å­¦ç¿’ |\n",
        "| Conservative | æµ…ã„æœ¨ + ä½å­¦ç¿’ç‡ | éå­¦ç¿’é˜²æ­¢ |\n",
        "\n",
        "### ğŸ“ è¨˜éŒ²ã™ã‚‹æƒ…å ±\n",
        "\n",
        "| ç¨®é¡ | å†…å®¹ | è¨˜éŒ²æ–¹æ³• |\n",
        "|------|------|----------|\n",
        "| ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ | ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ | `log_param()` |\n",
        "| ãƒ¡ãƒˆãƒªã‚¯ã‚¹ | Accuracy, F1ç­‰ | `log_metric()` |\n",
        "| ç‰¹å¾´é‡é‡è¦åº¦ | XGBoost Feature Importance | `log_metric()` |\n",
        "| SHAPå€¤ | å¹³å‡çµ¶å¯¾SHAPå€¤ | `log_metric()` |\n",
        "| ç”»åƒ | SHAP Summary Plot | `log_artifact()` |\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ac32ec67",
      "metadata": {},
      "outputs": [],
      "source": [
        "# å®Ÿé¨“è¨­å®šã®å®šç¾©\n",
        "import datetime\n",
        "timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "\n",
        "experiments = [\n",
        "    {\n",
        "        \"run_name\": f\"Baseline_{timestamp}\",\n",
        "        \"display_name\": \"Baseline\",\n",
        "        \"params\": {\n",
        "            \"max_depth\": 5,\n",
        "            \"learning_rate\": 0.1,\n",
        "            \"n_estimators\": 100,\n",
        "            \"scale_pos_weight\": 2\n",
        "        }\n",
        "    },\n",
        "    {\n",
        "        \"run_name\": f\"DeepTree_{timestamp}\",\n",
        "        \"display_name\": \"DeepTree\",\n",
        "        \"params\": {\n",
        "            \"max_depth\": 10,\n",
        "            \"learning_rate\": 0.1,\n",
        "            \"n_estimators\": 100,\n",
        "            \"scale_pos_weight\": 2\n",
        "        }\n",
        "    },\n",
        "    {\n",
        "        \"run_name\": f\"Conservative_{timestamp}\",\n",
        "        \"display_name\": \"Conservative\",\n",
        "        \"params\": {\n",
        "            \"max_depth\": 3,\n",
        "            \"learning_rate\": 0.05,\n",
        "            \"n_estimators\": 200,\n",
        "            \"scale_pos_weight\": 3\n",
        "        }\n",
        "    }\n",
        "]\n",
        "\n",
        "print(f\"âœ… {len(experiments)}ã¤ã®å®Ÿé¨“ã‚’å®šç¾©ã—ã¾ã—ãŸ\")\n",
        "print(f\"   ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—: {timestamp}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "18694265",
      "metadata": {},
      "outputs": [],
      "source": [
        "# å„å®Ÿé¨“ã®å®Ÿè¡Œã¨ãƒ­ã‚°è¨˜éŒ²\n",
        "results = []\n",
        "\n",
        "for experiment in experiments:\n",
        "    run_name = experiment[\"run_name\"]\n",
        "    display_name = experiment[\"display_name\"]\n",
        "    params = experiment[\"params\"]\n",
        "    \n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"Running: {display_name}\")\n",
        "    print(f\"{'='*60}\")\n",
        "    \n",
        "    # Experiment Trackingã§ãƒ©ãƒ³ã‚’é–‹å§‹\n",
        "    with exp.start_run(run_name=run_name):\n",
        "        \n",
        "        # ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’ãƒ­ã‚°\n",
        "        exp.log_param(\"model_type\", \"XGBoost\")\n",
        "        exp.log_param(\"display_name\", display_name)\n",
        "        for param_name, param_value in params.items():\n",
        "            exp.log_param(param_name, param_value)\n",
        "        \n",
        "        # ãƒ¢ãƒ‡ãƒ«ã®è¨“ç·´ï¼ˆsklearnç‰ˆXGBoostï¼‰\n",
        "        model = xgb.XGBClassifier(\n",
        "            random_state=42,\n",
        "            use_label_encoder=False,\n",
        "            eval_metric='logloss',\n",
        "            **params\n",
        "        )\n",
        "        model.fit(X_train, y_train)\n",
        "        \n",
        "        # äºˆæ¸¬ã¨è©•ä¾¡\n",
        "        y_pred = model.predict(X_test)\n",
        "        \n",
        "        # ãƒ¡ãƒˆãƒªã‚¯ã‚¹è¨ˆç®—\n",
        "        accuracy = accuracy_score(y_test, y_pred)\n",
        "        precision = precision_score(y_test, y_pred)\n",
        "        recall = recall_score(y_test, y_pred)\n",
        "        f1 = f1_score(y_test, y_pred)\n",
        "        \n",
        "        # ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’ãƒ­ã‚°\n",
        "        exp.log_metric(\"accuracy\", accuracy)\n",
        "        exp.log_metric(\"precision\", precision)\n",
        "        exp.log_metric(\"recall\", recall)\n",
        "        exp.log_metric(\"f1_score\", f1)\n",
        "        \n",
        "        # =====================================================\n",
        "        # ğŸ†• ç‰¹å¾´é‡é‡è¦åº¦ï¼ˆFeature Importanceï¼‰ã‚’è¨˜éŒ²\n",
        "        # =====================================================\n",
        "        feature_importance = model.feature_importances_\n",
        "        importance_dict = dict(zip(FEATURE_COLS, [float(v) for v in feature_importance]))\n",
        "        \n",
        "        # å„ç‰¹å¾´é‡ã®é‡è¦åº¦ã‚’å€‹åˆ¥ã®ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã¨ã—ã¦è¨˜éŒ²\n",
        "        for feature_name, importance in importance_dict.items():\n",
        "            exp.log_metric(f\"importance_{feature_name}\", importance)\n",
        "        \n",
        "        print(f\"\\n  ğŸ“Š ç‰¹å¾´é‡é‡è¦åº¦ (XGBoost):\")\n",
        "        for feat, imp in sorted(importance_dict.items(), key=lambda x: x[1], reverse=True)[:3]:\n",
        "            print(f\"    {feat}: {imp:.4f}\")\n",
        "        \n",
        "        # =====================================================\n",
        "        # ğŸ†• SHAPå€¤ã®è¨ˆç®—ã¨è¨˜éŒ²\n",
        "        # =====================================================\n",
        "        explainer = shap.TreeExplainer(model)\n",
        "        shap_values = explainer.shap_values(X_test)\n",
        "        \n",
        "        # SHAPå€¤ã®å¹³å‡çµ¶å¯¾å€¤ï¼ˆã‚°ãƒ­ãƒ¼ãƒãƒ«é‡è¦åº¦ï¼‰ã‚’è¨ˆç®—ãƒ»è¨˜éŒ²\n",
        "        shap_importance = np.abs(shap_values).mean(axis=0)\n",
        "        shap_dict = dict(zip(FEATURE_COLS, [float(v) for v in shap_importance]))\n",
        "        \n",
        "        for feature_name, shap_imp in shap_dict.items():\n",
        "            exp.log_metric(f\"shap_{feature_name}\", shap_imp)\n",
        "        \n",
        "        print(f\"\\n  ğŸ” SHAPå€¤ (å¹³å‡çµ¶å¯¾å€¤):\")\n",
        "        for feat, shap_val in sorted(shap_dict.items(), key=lambda x: x[1], reverse=True)[:3]:\n",
        "            print(f\"    {feat}: {shap_val:.4f}\")\n",
        "        \n",
        "        # =====================================================\n",
        "        # ğŸ†• SHAP Summary Plotã‚’ç”»åƒã¨ã—ã¦ä¿å­˜ãƒ»ã‚¢ãƒ¼ãƒ†ã‚£ãƒ•ã‚¡ã‚¯ãƒˆè¨˜éŒ²\n",
        "        # =====================================================\n",
        "        plt.figure(figsize=(10, 6))\n",
        "        shap.summary_plot(shap_values, X_test, feature_names=FEATURE_COLS, show=False)\n",
        "        plt.title(f\"SHAP Summary Plot - {display_name}\")\n",
        "        plt.tight_layout()\n",
        "        \n",
        "        # ç”»åƒã‚’ä¿å­˜\n",
        "        shap_plot_path = f\"/tmp/shap_summary_{display_name}.png\"\n",
        "        plt.savefig(shap_plot_path, bbox_inches='tight', dpi=150)\n",
        "        plt.close()\n",
        "        \n",
        "        # ã‚¢ãƒ¼ãƒ†ã‚£ãƒ•ã‚¡ã‚¯ãƒˆã¨ã—ã¦è¨˜éŒ²\n",
        "        exp.log_artifact(shap_plot_path)\n",
        "        print(f\"\\n  ğŸ“¸ SHAP Plotã‚’ä¿å­˜: {shap_plot_path}\")\n",
        "        \n",
        "        # çµæœã‚’ä¿å­˜\n",
        "        results.append({\n",
        "            \"run_name\": display_name,\n",
        "            \"accuracy\": accuracy,\n",
        "            \"precision\": precision,\n",
        "            \"recall\": recall,\n",
        "            \"f1_score\": f1,\n",
        "            \"model\": model,\n",
        "            \"params\": params,\n",
        "            \"feature_importance\": importance_dict,\n",
        "            \"shap_importance\": shap_dict,\n",
        "            \"shap_values\": shap_values\n",
        "        })\n",
        "        \n",
        "        print(f\"\\n  âœ… ãƒ¡ãƒˆãƒªã‚¯ã‚¹:\")\n",
        "        print(f\"    Accuracy:  {accuracy:.4f}\")\n",
        "        print(f\"    Precision: {precision:.4f}\")\n",
        "        print(f\"    Recall:    {recall:.4f}\")\n",
        "        print(f\"    F1 Score:  {f1:.4f}\")\n",
        "\n",
        "print(f\"\\nâœ… {len(experiments)}ã¤ã®å®Ÿé¨“ãŒå®Œäº†ã—ã¾ã—ãŸ\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "14e44461",
      "metadata": {},
      "source": [
        "---\n",
        "## 4.5 å®Ÿé¨“çµæœã®æ¯”è¼ƒ\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ffbf800c",
      "metadata": {},
      "outputs": [],
      "source": [
        "# çµæœã‚’DataFrameã§æ¯”è¼ƒ\n",
        "results_df = pd.DataFrame([{\n",
        "    \"Run\": r[\"run_name\"],\n",
        "    \"Accuracy\": f\"{r['accuracy']:.4f}\",\n",
        "    \"Precision\": f\"{r['precision']:.4f}\",\n",
        "    \"Recall\": f\"{r['recall']:.4f}\",\n",
        "    \"F1 Score\": f\"{r['f1_score']:.4f}\"\n",
        "} for r in results])\n",
        "\n",
        "print(\"=\" * 70)\n",
        "print(\"ğŸ“Š å®Ÿé¨“çµæœã®æ¯”è¼ƒ\")\n",
        "print(\"=\" * 70)\n",
        "print(results_df.to_string(index=False))\n",
        "print(\"=\" * 70)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e5c82a16",
      "metadata": {},
      "outputs": [],
      "source": [
        "# æœ€è‰¯ãƒ¢ãƒ‡ãƒ«ã®é¸æŠï¼ˆF1ã‚¹ã‚³ã‚¢åŸºæº–ï¼‰\n",
        "best_result = max(results, key=lambda x: x[\"f1_score\"])\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"ğŸ† æœ€è‰¯ãƒ¢ãƒ‡ãƒ«ï¼ˆF1ã‚¹ã‚³ã‚¢åŸºæº–ï¼‰\")\n",
        "print(\"=\" * 60)\n",
        "print(f\"  Run Name:  {best_result['run_name']}\")\n",
        "print(f\"  F1 Score:  {best_result['f1_score']:.4f}\")\n",
        "print(f\"  Accuracy:  {best_result['accuracy']:.4f}\")\n",
        "print(f\"  Precision: {best_result['precision']:.4f}\")\n",
        "print(f\"  Recall:    {best_result['recall']:.4f}\")\n",
        "print(\"=\"  * 60)\n",
        "print(f\"  ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿: {best_result['params']}\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# æœ€è‰¯ãƒ¢ãƒ‡ãƒ«ã®ç‰¹å¾´é‡é‡è¦åº¦ã‚’è¡¨ç¤º\n",
        "print(\"\\nğŸ“Š æœ€è‰¯ãƒ¢ãƒ‡ãƒ«ã®ç‰¹å¾´é‡é‡è¦åº¦ï¼ˆä¸Šä½5ä»¶ï¼‰:\")\n",
        "sorted_importance = sorted(best_result['feature_importance'].items(), key=lambda x: x[1], reverse=True)\n",
        "for feat, imp in sorted_importance[:5]:\n",
        "    print(f\"  {feat}: {imp:.4f}\")\n",
        "\n",
        "print(\"\\nğŸ” æœ€è‰¯ãƒ¢ãƒ‡ãƒ«ã®SHAPå€¤ï¼ˆä¸Šä½5ä»¶ï¼‰:\")\n",
        "sorted_shap = sorted(best_result['shap_importance'].items(), key=lambda x: x[1], reverse=True)\n",
        "for feat, shap_val in sorted_shap[:5]:\n",
        "    print(f\"  {feat}: {shap_val:.4f}\")\n",
        "\n",
        "# æœ€è‰¯ãƒ¢ãƒ‡ãƒ«ã‚’ä¿å­˜\n",
        "best_model = best_result[\"model\"]\n",
        "best_metrics = {\n",
        "    \"accuracy\": best_result[\"accuracy\"],\n",
        "    \"precision\": best_result[\"precision\"],\n",
        "    \"recall\": best_result[\"recall\"],\n",
        "    \"f1_score\": best_result[\"f1_score\"]\n",
        "}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "73a86440",
      "metadata": {},
      "source": [
        "---\n",
        "## 4.6 å¯è¦–åŒ–\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5440ece9",
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# å®Ÿé¨“çµæœã®ãƒãƒ¼ãƒãƒ£ãƒ¼ãƒˆ\n",
        "metrics = [\"accuracy\", \"precision\", \"recall\", \"f1_score\"]\n",
        "run_names = [r[\"run_name\"] for r in results]\n",
        "\n",
        "fig, axes = plt.subplots(1, 4, figsize=(14, 4))\n",
        "\n",
        "for i, metric in enumerate(metrics):\n",
        "    values = [r[metric] for r in results]\n",
        "    colors = ['gold' if r[\"run_name\"] == best_result[\"run_name\"] else 'steelblue' for r in results]\n",
        "    axes[i].bar(run_names, values, color=colors)\n",
        "    axes[i].set_title(metric.replace('_', ' ').title())\n",
        "    axes[i].set_ylim(0, 1)\n",
        "    axes[i].tick_params(axis='x', rotation=45)\n",
        "\n",
        "plt.suptitle('Experiment Results Comparison', fontsize=14, fontweight='bold')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "339361c0",
      "metadata": {},
      "outputs": [],
      "source": [
        "# æœ€è‰¯ãƒ¢ãƒ‡ãƒ«ã®SHAP Summary Plotã‚’è¡¨ç¤º\n",
        "print(f\"=== ğŸ” æœ€è‰¯ãƒ¢ãƒ‡ãƒ«ï¼ˆ{best_result['run_name']}ï¼‰ã®SHAP Summary Plot ===\")\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "shap.summary_plot(\n",
        "    best_result['shap_values'], \n",
        "    X_test, \n",
        "    feature_names=FEATURE_COLS,\n",
        "    show=False\n",
        ")\n",
        "plt.title(f\"SHAP Summary Plot - {best_result['run_name']}\", fontsize=14, fontweight='bold')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nğŸ’¡ ã“ã®ãƒ—ãƒ­ãƒƒãƒˆã®è¦‹æ–¹:\")\n",
        "print(\"   - æ¨ªè»¸: SHAPå€¤ï¼ˆäºˆæ¸¬ã¸ã®å½±éŸ¿åº¦ï¼‰\")\n",
        "print(\"   - ç¸¦è»¸: ç‰¹å¾´é‡ï¼ˆé‡è¦åº¦é †ï¼‰\")\n",
        "print(\"   - è‰²: ç‰¹å¾´é‡ã®å€¤ï¼ˆèµ¤=é«˜ã€é’=ä½ï¼‰\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a74c40ae",
      "metadata": {},
      "source": [
        "---\n",
        "## 4.7 å®Ÿé¨“çµæœã®æ°¸ç¶šåŒ–\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "49d3f1bc",
      "metadata": {},
      "outputs": [],
      "source": [
        "# å®Ÿé¨“çµæœã‚’ãƒ†ãƒ¼ãƒ–ãƒ«ã«ä¿å­˜ï¼ˆè£œåŠ©çš„ãªè¨˜éŒ²ï¼‰\n",
        "import datetime\n",
        "\n",
        "experiment_records = []\n",
        "for r in results:\n",
        "    experiment_records.append({\n",
        "        \"EXPERIMENT_NAME\": EXPERIMENT_NAME,\n",
        "        \"RUN_NAME\": r[\"run_name\"],\n",
        "        \"ACCURACY\": r[\"accuracy\"],\n",
        "        \"PRECISION\": r[\"precision\"],\n",
        "        \"RECALL\": r[\"recall\"],\n",
        "        \"F1_SCORE\": r[\"f1_score\"],\n",
        "        \"PARAMS\": json.dumps(r[\"params\"]),\n",
        "        \"FEATURE_IMPORTANCE\": json.dumps(r[\"feature_importance\"]),  # ğŸ†• ç‰¹å¾´é‡é‡è¦åº¦\n",
        "        \"SHAP_IMPORTANCE\": json.dumps(r[\"shap_importance\"]),        # ğŸ†• SHAPå€¤\n",
        "        \"CREATED_AT\": datetime.datetime.now().isoformat()\n",
        "    })\n",
        "\n",
        "records_df = session.create_dataframe(experiment_records)\n",
        "records_df.write.save_as_table(\n",
        "    \"MLOPS_HOL_DB.FEATURE_STORE.EXPERIMENT_RESULTS\",\n",
        "    mode=\"overwrite\"\n",
        ")\n",
        "\n",
        "print(\"âœ… å®Ÿé¨“çµæœã‚’ãƒ†ãƒ¼ãƒ–ãƒ«ã«ä¿å­˜ã—ã¾ã—ãŸ\")\n",
        "print(\"   ãƒ†ãƒ¼ãƒ–ãƒ«: MLOPS_HOL_DB.FEATURE_STORE.EXPERIMENT_RESULTS\")\n",
        "print(\"\\nğŸ“ ä¿å­˜ã•ã‚ŒãŸé …ç›®:\")\n",
        "print(\"   - ãƒ¡ãƒˆãƒªã‚¯ã‚¹ï¼ˆAccuracy, Precision, Recall, F1ï¼‰\")\n",
        "print(\"   - ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼ˆJSONï¼‰\")\n",
        "print(\"   - ç‰¹å¾´é‡é‡è¦åº¦ï¼ˆJSONï¼‰\")\n",
        "print(\"   - SHAPå€¤ï¼ˆJSONï¼‰\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c932a35a",
      "metadata": {},
      "source": [
        "---\n",
        "## âœ… Section 4 å®Œäº†ï¼\n",
        "\n",
        "### å­¦ã‚“ã ã“ã¨\n",
        "- **Snowflake ML ExperimentTracking** ã®ä½¿ã„æ–¹\n",
        "- `exp.set_experiment()` ã§å®Ÿé¨“ã‚’ä½œæˆ\n",
        "- `exp.start_run()` ã§ãƒ©ãƒ³ã‚’é–‹å§‹\n",
        "- `exp.log_param()`, `exp.log_metric()` ã§ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒ»ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’è¨˜éŒ²\n",
        "- è¤‡æ•°å®Ÿé¨“ã®æ¯”è¼ƒã¨æœ€è‰¯ãƒ¢ãƒ‡ãƒ«ã®é¸æŠ\n",
        "\n",
        "### ğŸ“ è¨˜éŒ²ã—ãŸæƒ…å ±\n",
        "\n",
        "| ãƒ¡ã‚½ãƒƒãƒ‰ | è¨˜éŒ²å†…å®¹ | ç”¨é€” |\n",
        "|---------|---------|------|\n",
        "| `log_param()` | ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ | ãƒ¢ãƒ‡ãƒ«è¨­å®šã®è¿½è·¡ |\n",
        "| `log_metric()` | Accuracy, F1ç­‰ | æ€§èƒ½è©•ä¾¡ |\n",
        "| `log_metric()` | ç‰¹å¾´é‡é‡è¦åº¦ | ãƒ¢ãƒ‡ãƒ«è§£é‡ˆæ€§ |\n",
        "| `log_metric()` | SHAPå€¤ | äºˆæ¸¬æ ¹æ‹ ã®èª¬æ˜ |\n",
        "| `log_artifact()` | SHAP Summary Plot | å¯è¦–åŒ–ã®ä¿å­˜ |\n",
        "\n",
        "### ä½œæˆã—ãŸã‚‚ã®\n",
        "- Experiment: `CHURN_PREDICTION_EXPERIMENT`\n",
        "- 3ã¤ã®Run: Baseline, DeepTree, Conservative\n",
        "- å®Ÿé¨“çµæœãƒ†ãƒ¼ãƒ–ãƒ«: `EXPERIMENT_RESULTS`\n",
        "  - ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã€ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã€ç‰¹å¾´é‡é‡è¦åº¦ã€SHAPå€¤ï¼ˆJSONå½¢å¼ï¼‰\n",
        "- SHAP Summary Plotç”»åƒï¼ˆã‚¢ãƒ¼ãƒ†ã‚£ãƒ•ã‚¡ã‚¯ãƒˆï¼‰\n",
        "\n",
        "### ğŸ’¡ å¾Œã‹ã‚‰æŒ¯ã‚Šè¿”ã‚‹ã¨ãã®ãƒã‚¤ãƒ³ãƒˆ\n",
        "\n",
        "```sql\n",
        "-- å®Ÿé¨“çµæœãƒ†ãƒ¼ãƒ–ãƒ«ã‹ã‚‰ç‰¹å¾´é‡é‡è¦åº¦ã‚’ç¢ºèª\n",
        "SELECT \n",
        "    RUN_NAME,\n",
        "    F1_SCORE,\n",
        "    FEATURE_IMPORTANCE,\n",
        "    SHAP_IMPORTANCE\n",
        "FROM MLOPS_HOL_DB.FEATURE_STORE.EXPERIMENT_RESULTS\n",
        "ORDER BY F1_SCORE DESC;\n",
        "```\n",
        "\n",
        "### æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—\n",
        "**Section 5: Model Registry** ã§ã¯ã€æœ€è‰¯ãƒ¢ãƒ‡ãƒ«ã‚’ç™»éŒ²ã—ã€\n",
        "ãƒãƒ¼ã‚¸ãƒ§ãƒ³ç®¡ç†ã¨æœ¬ç•ªãƒ‡ãƒ—ãƒ­ã‚¤ã®æº–å‚™ã‚’è¡Œã„ã¾ã™ã€‚\n",
        "\n",
        "â¡ï¸ `05_MODEL_REGISTRY` Notebookã«é€²ã‚“ã§ãã ã•ã„\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
