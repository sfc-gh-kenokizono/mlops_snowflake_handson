{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "8d68ef96",
      "metadata": {},
      "source": [
        "# Section 4: Experiment Trackingï¼ˆå®Ÿé¨“ç®¡ç†ï¼‰\n",
        "\n",
        "## ğŸ¯ ã“ã®ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã®ç›®æ¨™\n",
        "- **Snowflake ML Experiments** ã‚’ä½¿ã£ãŸå®Ÿé¨“ç®¡ç†ã‚’å­¦ã¶\n",
        "- è¤‡æ•°ãƒ¢ãƒ‡ãƒ«ã®æ¯”è¼ƒå®Ÿé¨“ã‚’è¡Œã†\n",
        "- ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒ»ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’è¨˜éŒ²ã—ã¦è¿½è·¡ã™ã‚‹\n",
        "\n",
        "## ğŸ“‹ Experiment Trackingã¨ã¯ï¼Ÿ\n",
        "æ©Ÿæ¢°å­¦ç¿’ã®å®Ÿé¨“ã‚’ä½“ç³»çš„ã«ç®¡ç†ã™ã‚‹ãŸã‚ã®æ©Ÿèƒ½ã§ã™ï¼š\n",
        "- ãƒ¢ãƒ‡ãƒ«ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã¨çµæœã‚’è¨˜éŒ²\n",
        "- è¤‡æ•°ã®å®Ÿé¨“ã‚’æ¯”è¼ƒ\n",
        "- å†ç¾æ€§ã®ã‚ã‚‹å®Ÿé¨“ç’°å¢ƒã‚’æ§‹ç¯‰\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ’¡ ãƒãƒ³ã‚ºã‚ªãƒ³ã§ã®ä½ç½®ã¥ã‘\n",
        "\n",
        "ã“ã®ãƒãƒ³ã‚ºã‚ªãƒ³ã§ã¯ã€**å„æ©Ÿèƒ½ã‚’ç‹¬ç«‹ã—ã¦å­¦ã¶**ã“ã¨ã‚’ç›®çš„ã¨ã—ã¦ã„ã¾ã™ã€‚\n",
        "\n",
        "| Section | å­¦ç¿’ç›®çš„ |\n",
        "|---------|----------|\n",
        "| 03 Model Training | ãƒã‚¤ãƒ‘ãƒ©**è‡ªå‹•æ¢ç´¢**ï¼ˆRandomizedSearchCVï¼‰ |\n",
        "| 04 Experiment Tracking | å®Ÿé¨“ã®**è¨˜éŒ²ãƒ»æ¯”è¼ƒ**æ©Ÿèƒ½ |\n",
        "\n",
        "ãã®ãŸã‚ã€03ã§è¦‹ã¤ã‘ãŸæœ€è‰¯ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã¨ã¯**åˆ¥ã«**ã€ç•°ãªã‚‹ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§å®Ÿé¨“ã‚’è¡Œã„ã€Experiment Trackingã®æ©Ÿèƒ½ã‚’ä½“é¨“ã—ã¾ã™ã€‚\n",
        "\n",
        "> ğŸ“ **å®Ÿé‹ç”¨ã§ã¯**: RandomizedSearchCVã®å„ã‚¤ãƒ†ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³çµæœã‚’Experiment Trackingã«è¨˜éŒ²ã—ã€ä¸€å…ƒç®¡ç†ã™ã‚‹ã“ã¨ãŒå¤šã„ã§ã™ã€‚\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "257b5f64",
      "metadata": {},
      "source": [
        "---\n",
        "## 4.1 ç’°å¢ƒè¨­å®š\n",
        "\n",
        "> ğŸ’¡ **ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã«ã¤ã„ã¦**: `environment.yml` ã«ã‚ˆã‚Šå¿…è¦ãªãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ï¼ˆsnowflake-ml-pythonç­‰ï¼‰ã¯è‡ªå‹•çš„ã«ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã¾ã™ã€‚\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "62e3d7ef",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Warningã‚’æŠ‘åˆ¶ï¼ˆãƒãƒ³ã‚ºã‚ªãƒ³å‘ã‘ï¼‰\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "from snowflake.snowpark.context import get_active_session\n",
        "from snowflake.snowpark import functions as F\n",
        "from snowflake.snowpark.types import *\n",
        "\n",
        "# MLé–¢é€£ï¼ˆsklearnç‰ˆã‚’ä½¿ç”¨ - ã‚³ãƒ³ãƒ†ãƒŠãƒ©ãƒ³ã‚¿ã‚¤ãƒ äº’æ›æ€§ã®ãŸã‚ï¼‰\n",
        "import xgboost as xgb\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, precision_score, recall_score, f1_score,\n",
        "    roc_auc_score, confusion_matrix  # ğŸ†• è¿½åŠ \n",
        ")\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import json\n",
        "import time  # ğŸ†• å®Ÿè¡Œæ™‚é–“è¨ˆæ¸¬ç”¨\n",
        "\n",
        "# å¯è¦–åŒ–\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns  # ğŸ†• Confusion Matrixç”¨\n",
        "\n",
        "# SHAPï¼ˆãƒ¢ãƒ‡ãƒ«è§£é‡ˆæ€§ï¼‰\n",
        "import shap\n",
        "\n",
        "# Experiment Tracking\n",
        "from snowflake.ml.experiment import ExperimentTracking\n",
        "\n",
        "# ã‚»ãƒƒã‚·ãƒ§ãƒ³ã®å–å¾—\n",
        "session = get_active_session()\n",
        "\n",
        "# ç’°å¢ƒè¨­å®š\n",
        "session.use_database(\"MLOPS_HOL_DB\")\n",
        "session.use_schema(\"FEATURE_STORE\")\n",
        "session.use_warehouse(\"MLOPS_HOL_SQL_WH\")\n",
        "\n",
        "print(\"âœ… ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆå®Œäº†\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3414f11f",
      "metadata": {},
      "source": [
        "---\n",
        "## 4.2 Experiment Trackingã®åˆæœŸåŒ–\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0bdd1802",
      "metadata": {},
      "outputs": [],
      "source": [
        "# ExperimentTracking ã®ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹åŒ–\n",
        "exp = ExperimentTracking(session=session)\n",
        "\n",
        "# å®Ÿé¨“åã‚’è¨­å®š\n",
        "EXPERIMENT_NAME = \"CHURN_PREDICTION_EXPERIMENT\"\n",
        "exp.set_experiment(EXPERIMENT_NAME)\n",
        "\n",
        "print(f\"âœ… Experimentè¨­å®šå®Œäº†: {EXPERIMENT_NAME}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "67104cb6",
      "metadata": {},
      "source": [
        "---\n",
        "## 4.3 å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã®æº–å‚™\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aba30f07",
      "metadata": {},
      "outputs": [],
      "source": [
        "# å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’èª­ã¿è¾¼ã¿\n",
        "DATASET_NAME = \"TRAINING_DATASET_V1\"  # ğŸ†• ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆåã‚’å¤‰æ•°åŒ–\n",
        "training_data = session.table(DATASET_NAME)\n",
        "\n",
        "# ç‰¹å¾´é‡ã¨ãƒ©ãƒ™ãƒ«ã®å®šç¾©\n",
        "FEATURE_COLS = [\n",
        "    \"DAYS_SINCE_LAST_ORDER\",\n",
        "    \"TOTAL_ORDER_COUNT\",\n",
        "    \"ORDER_COUNT_2024_H1\",\n",
        "    \"TOTAL_ORDER_AMOUNT\",\n",
        "    \"AVG_ORDER_AMOUNT\",\n",
        "    \"TOTAL_AMOUNT_2024_H1\",\n",
        "    \"RETURN_RATE\"\n",
        "]\n",
        "LABEL_COL = \"IS_CHURNED\"\n",
        "ID_COL = \"CUSTOMER_ID\"\n",
        "\n",
        "# ãƒ‡ãƒ¼ã‚¿ã®åˆ†å‰²\n",
        "model_data = training_data.select([ID_COL] + FEATURE_COLS + [LABEL_COL])\n",
        "train_sf, test_sf = model_data.random_split(weights=[0.8, 0.2], seed=42)\n",
        "\n",
        "# Pandas DataFrameã«å¤‰æ›ï¼ˆsklearnç”¨ï¼‰\n",
        "train_pd = train_sf.to_pandas()\n",
        "test_pd = test_sf.to_pandas()\n",
        "\n",
        "X_train = train_pd[FEATURE_COLS]\n",
        "y_train = train_pd[LABEL_COL]\n",
        "X_test = test_pd[FEATURE_COLS]\n",
        "y_test = test_pd[LABEL_COL]\n",
        "\n",
        "# ğŸ†• ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆæƒ…å ±ã®è¨ˆç®—\n",
        "total_samples = len(train_pd) + len(test_pd)\n",
        "train_churn_rate = y_train.mean()\n",
        "test_churn_rate = y_test.mean()\n",
        "\n",
        "# ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆæƒ…å ±ã‚’è¾æ›¸ã«ä¿å­˜ï¼ˆå¾Œã§Experiment Trackingã«è¨˜éŒ²ï¼‰\n",
        "dataset_info = {\n",
        "    \"dataset_name\": DATASET_NAME,\n",
        "    \"total_samples\": total_samples,\n",
        "    \"train_samples\": len(train_pd),\n",
        "    \"test_samples\": len(test_pd),\n",
        "    \"num_features\": len(FEATURE_COLS),\n",
        "    \"train_churn_rate\": float(train_churn_rate),\n",
        "    \"test_churn_rate\": float(test_churn_rate)\n",
        "}\n",
        "\n",
        "print(f\"ğŸ“Š ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆæƒ…å ±\")\n",
        "print(f\"   ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ: {DATASET_NAME}\")\n",
        "print(f\"   è¨“ç·´ãƒ‡ãƒ¼ã‚¿: {len(train_pd):,} ä»¶ (ãƒãƒ£ãƒ¼ãƒ³ç‡: {train_churn_rate:.1%})\")\n",
        "print(f\"   ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿: {len(test_pd):,} ä»¶ (ãƒãƒ£ãƒ¼ãƒ³ç‡: {test_churn_rate:.1%})\")\n",
        "print(f\"   ç‰¹å¾´é‡æ•°: {len(FEATURE_COLS)} å€‹\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f3eb49a2",
      "metadata": {},
      "source": [
        "---\n",
        "## 4.4 å®Ÿé¨“ã®å®Ÿè¡Œ\n",
        "\n",
        "è¤‡æ•°ã®ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§ãƒ¢ãƒ‡ãƒ«ã‚’è¨“ç·´ã—ã€çµæœã‚’è¨˜éŒ²ã—ã¾ã™ã€‚\n",
        "\n",
        "| Run | ç‰¹å¾´ | æœŸå¾… |\n",
        "|-----|------|------|\n",
        "| Baseline | ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ | åŸºæº–ãƒ¢ãƒ‡ãƒ« |\n",
        "| DeepTree | æ·±ã„æœ¨ (max_depth=10) | è¤‡é›‘ãªãƒ‘ã‚¿ãƒ¼ãƒ³å­¦ç¿’ |\n",
        "| Conservative | æµ…ã„æœ¨ + ä½å­¦ç¿’ç‡ | éå­¦ç¿’é˜²æ­¢ |\n",
        "\n",
        "### ğŸ“ è¨˜éŒ²ã™ã‚‹æƒ…å ±\n",
        "\n",
        "| ç¨®é¡ | å†…å®¹ | è¨˜éŒ²æ–¹æ³• |\n",
        "|------|------|----------|\n",
        "| ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ | ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ | `log_param()` |\n",
        "| ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆæƒ…å ± | ãƒ‡ãƒ¼ã‚¿ä»¶æ•°ã€ãƒãƒ£ãƒ¼ãƒ³ç‡ | `log_param()` |\n",
        "| ãƒ¡ãƒˆãƒªã‚¯ã‚¹ | Accuracy, F1, **ROC-AUC** | `log_metric()` |\n",
        "| å®Ÿè¡Œæ™‚é–“ | å­¦ç¿’ã«ã‹ã‹ã£ãŸæ™‚é–“ | `log_metric()` |\n",
        "| ç‰¹å¾´é‡é‡è¦åº¦ | XGBoost Feature Importance | `log_metric()` |\n",
        "| SHAPå€¤ | å¹³å‡çµ¶å¯¾SHAPå€¤ | `log_metric()` |\n",
        "| ç”»åƒ | Confusion Matrix, Feature Importanceæ£’ã‚°ãƒ©ãƒ•, SHAP Summary Plot | `log_artifact()` |\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ac32ec67",
      "metadata": {},
      "outputs": [],
      "source": [
        "# å®Ÿé¨“è¨­å®šã®å®šç¾©\n",
        "import datetime\n",
        "timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "\n",
        "experiments = [\n",
        "    {\n",
        "        \"run_name\": f\"Baseline_{timestamp}\",\n",
        "        \"display_name\": \"Baseline\",\n",
        "        \"params\": {\n",
        "            \"max_depth\": 5,\n",
        "            \"learning_rate\": 0.1,\n",
        "            \"n_estimators\": 100,\n",
        "            \"scale_pos_weight\": 2\n",
        "        }\n",
        "    },\n",
        "    {\n",
        "        \"run_name\": f\"DeepTree_{timestamp}\",\n",
        "        \"display_name\": \"DeepTree\",\n",
        "        \"params\": {\n",
        "            \"max_depth\": 10,\n",
        "            \"learning_rate\": 0.1,\n",
        "            \"n_estimators\": 100,\n",
        "            \"scale_pos_weight\": 2\n",
        "        }\n",
        "    },\n",
        "    {\n",
        "        \"run_name\": f\"Conservative_{timestamp}\",\n",
        "        \"display_name\": \"Conservative\",\n",
        "        \"params\": {\n",
        "            \"max_depth\": 3,\n",
        "            \"learning_rate\": 0.05,\n",
        "            \"n_estimators\": 200,\n",
        "            \"scale_pos_weight\": 3\n",
        "        }\n",
        "    }\n",
        "]\n",
        "\n",
        "print(f\"âœ… {len(experiments)}ã¤ã®å®Ÿé¨“ã‚’å®šç¾©ã—ã¾ã—ãŸ\")\n",
        "print(f\"   ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—: {timestamp}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "18694265",
      "metadata": {},
      "outputs": [],
      "source": [
        "# å„å®Ÿé¨“ã®å®Ÿè¡Œã¨ãƒ­ã‚°è¨˜éŒ²\n",
        "results = []\n",
        "\n",
        "for experiment in experiments:\n",
        "    run_name = experiment[\"run_name\"]\n",
        "    display_name = experiment[\"display_name\"]\n",
        "    params = experiment[\"params\"]\n",
        "    \n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"Running: {display_name}\")\n",
        "    print(f\"{'='*60}\")\n",
        "    \n",
        "    # Experiment Trackingã§ãƒ©ãƒ³ã‚’é–‹å§‹\n",
        "    with exp.start_run(run_name=run_name):\n",
        "        \n",
        "        # ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’ãƒ­ã‚°\n",
        "        exp.log_param(\"model_type\", \"XGBoost\")\n",
        "        exp.log_param(\"display_name\", display_name)\n",
        "        for param_name, param_value in params.items():\n",
        "            exp.log_param(param_name, param_value)\n",
        "        \n",
        "        # ğŸ†• ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆæƒ…å ±ã‚’ãƒ­ã‚°\n",
        "        for key, value in dataset_info.items():\n",
        "            exp.log_param(key, value)\n",
        "        \n",
        "        # ğŸ†• å®Ÿè¡Œæ™‚é–“ã®è¨ˆæ¸¬é–‹å§‹\n",
        "        start_time = time.time()\n",
        "        \n",
        "        # ãƒ¢ãƒ‡ãƒ«ã®è¨“ç·´ï¼ˆsklearnç‰ˆXGBoostï¼‰\n",
        "        model = xgb.XGBClassifier(\n",
        "            random_state=42,\n",
        "            use_label_encoder=False,\n",
        "            eval_metric='logloss',\n",
        "            **params\n",
        "        )\n",
        "        model.fit(X_train, y_train)\n",
        "        \n",
        "        # ğŸ†• å®Ÿè¡Œæ™‚é–“ã®è¨ˆæ¸¬çµ‚äº†\n",
        "        training_time = time.time() - start_time\n",
        "        exp.log_metric(\"training_time_sec\", training_time)\n",
        "        \n",
        "        # äºˆæ¸¬ã¨è©•ä¾¡\n",
        "        y_pred = model.predict(X_test)\n",
        "        y_pred_proba = model.predict_proba(X_test)[:, 1]  # ğŸ†• ç¢ºç‡äºˆæ¸¬\n",
        "        \n",
        "        # ãƒ¡ãƒˆãƒªã‚¯ã‚¹è¨ˆç®—\n",
        "        accuracy = accuracy_score(y_test, y_pred)\n",
        "        precision = precision_score(y_test, y_pred)\n",
        "        recall = recall_score(y_test, y_pred)\n",
        "        f1 = f1_score(y_test, y_pred)\n",
        "        roc_auc = roc_auc_score(y_test, y_pred_proba)  # ğŸ†• ROC-AUC\n",
        "        \n",
        "        # ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’ãƒ­ã‚°\n",
        "        exp.log_metric(\"accuracy\", accuracy)\n",
        "        exp.log_metric(\"precision\", precision)\n",
        "        exp.log_metric(\"recall\", recall)\n",
        "        exp.log_metric(\"f1_score\", f1)\n",
        "        exp.log_metric(\"roc_auc\", roc_auc)  # ğŸ†•\n",
        "        \n",
        "        # =====================================================\n",
        "        # ğŸ†• Confusion Matrixï¼ˆæ··åŒè¡Œåˆ—ï¼‰ã®è¨ˆç®—ã¨ä¿å­˜\n",
        "        # =====================================================\n",
        "        cm = confusion_matrix(y_test, y_pred)\n",
        "        \n",
        "        # Confusion Matrixã‚’ãƒ—ãƒ­ãƒƒãƒˆ\n",
        "        plt.figure(figsize=(8, 6))\n",
        "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "                    xticklabels=['Non-Churn', 'Churn'],\n",
        "                    yticklabels=['Non-Churn', 'Churn'])\n",
        "        plt.title(f'Confusion Matrix - {display_name}')\n",
        "        plt.ylabel('Actual')\n",
        "        plt.xlabel('Predicted')\n",
        "        plt.tight_layout()\n",
        "        \n",
        "        # ç”»åƒã‚’ä¿å­˜\n",
        "        cm_plot_path = f\"/tmp/confusion_matrix_{display_name}.png\"\n",
        "        plt.savefig(cm_plot_path, bbox_inches='tight', dpi=150)\n",
        "        plt.close()\n",
        "        \n",
        "        # ã‚¢ãƒ¼ãƒ†ã‚£ãƒ•ã‚¡ã‚¯ãƒˆã¨ã—ã¦è¨˜éŒ²\n",
        "        exp.log_artifact(cm_plot_path)\n",
        "        \n",
        "        # Confusion Matrixã®æ•°å€¤ã‚‚è¨˜éŒ²\n",
        "        tn, fp, fn, tp = cm.ravel()\n",
        "        exp.log_metric(\"true_negatives\", int(tn))\n",
        "        exp.log_metric(\"false_positives\", int(fp))\n",
        "        exp.log_metric(\"false_negatives\", int(fn))\n",
        "        exp.log_metric(\"true_positives\", int(tp))\n",
        "        \n",
        "        print(f\"\\n  ğŸ“Š Confusion Matrix:\")\n",
        "        print(f\"    TN: {tn}, FP: {fp}\")\n",
        "        print(f\"    FN: {fn}, TP: {tp}\")\n",
        "        \n",
        "        # =====================================================\n",
        "        # ç‰¹å¾´é‡é‡è¦åº¦ï¼ˆFeature Importanceï¼‰ã‚’è¨˜éŒ²\n",
        "        # =====================================================\n",
        "        feature_importance = model.feature_importances_\n",
        "        importance_dict = dict(zip(FEATURE_COLS, [float(v) for v in feature_importance]))\n",
        "        \n",
        "        # å„ç‰¹å¾´é‡ã®é‡è¦åº¦ã‚’å€‹åˆ¥ã®ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã¨ã—ã¦è¨˜éŒ²\n",
        "        for feature_name, importance in importance_dict.items():\n",
        "            exp.log_metric(f\"importance_{feature_name}\", importance)\n",
        "        \n",
        "        print(f\"\\n  ğŸ“Š ç‰¹å¾´é‡é‡è¦åº¦ (XGBoost):\")\n",
        "        for feat, imp in sorted(importance_dict.items(), key=lambda x: x[1], reverse=True)[:3]:\n",
        "            print(f\"    {feat}: {imp:.4f}\")\n",
        "        \n",
        "        # ğŸ†• Feature Importanceæ£’ã‚°ãƒ©ãƒ•ã‚’ç”»åƒã¨ã—ã¦ä¿å­˜\n",
        "        sorted_imp = sorted(importance_dict.items(), key=lambda x: x[1], reverse=True)\n",
        "        fig, ax = plt.subplots(figsize=(10, 6))\n",
        "        features = [x[0] for x in sorted_imp]\n",
        "        importances = [x[1] for x in sorted_imp]\n",
        "        colors = plt.cm.Blues(np.linspace(0.8, 0.3, len(features)))\n",
        "        ax.barh(features[::-1], importances[::-1], color=colors[::-1])\n",
        "        ax.set_xlabel('Feature Importance')\n",
        "        ax.set_title(f'Feature Importance - {display_name}', fontsize=14, fontweight='bold')\n",
        "        for i, v in enumerate(importances[::-1]):\n",
        "            ax.text(v + 0.01, i, f'{v:.3f}', va='center', fontsize=9)\n",
        "        plt.tight_layout()\n",
        "        \n",
        "        fi_plot_path = f\"/tmp/feature_importance_{display_name}.png\"\n",
        "        plt.savefig(fi_plot_path, bbox_inches='tight', dpi=150)\n",
        "        plt.close()\n",
        "        exp.log_artifact(fi_plot_path)\n",
        "        \n",
        "        # =====================================================\n",
        "        # SHAPå€¤ã®è¨ˆç®—ã¨è¨˜éŒ²\n",
        "        # =====================================================\n",
        "        explainer = shap.TreeExplainer(model)\n",
        "        shap_values = explainer.shap_values(X_test)\n",
        "        \n",
        "        # SHAPå€¤ã®å¹³å‡çµ¶å¯¾å€¤ï¼ˆã‚°ãƒ­ãƒ¼ãƒãƒ«é‡è¦åº¦ï¼‰ã‚’è¨ˆç®—ãƒ»è¨˜éŒ²\n",
        "        shap_importance = np.abs(shap_values).mean(axis=0)\n",
        "        shap_dict = dict(zip(FEATURE_COLS, [float(v) for v in shap_importance]))\n",
        "        \n",
        "        for feature_name, shap_imp in shap_dict.items():\n",
        "            exp.log_metric(f\"shap_{feature_name}\", shap_imp)\n",
        "        \n",
        "        print(f\"\\n  ğŸ” SHAPå€¤ (å¹³å‡çµ¶å¯¾å€¤):\")\n",
        "        for feat, shap_val in sorted(shap_dict.items(), key=lambda x: x[1], reverse=True)[:3]:\n",
        "            print(f\"    {feat}: {shap_val:.4f}\")\n",
        "        \n",
        "        # ğŸ†• SHAPå€¤ã®å®Œå…¨ãƒ‡ãƒ¼ã‚¿ã‚’CSVã¨ã—ã¦ä¿å­˜ï¼ˆå¾Œã‹ã‚‰å†ç¾å¯èƒ½ã«ï¼‰\n",
        "        shap_full_df = pd.DataFrame(shap_values, columns=[f\"shap_{col}\" for col in FEATURE_COLS])\n",
        "        # ç‰¹å¾´é‡ã®å®Ÿéš›ã®å€¤ã‚‚è¿½åŠ ï¼ˆSummary Plotã®è‰²æƒ…å ±å†ç¾ç”¨ï¼‰\n",
        "        for col in FEATURE_COLS:\n",
        "            shap_full_df[f\"value_{col}\"] = X_test[col].values\n",
        "        shap_csv_path = f\"/tmp/shap_full_data_{display_name}.csv\"\n",
        "        shap_full_df.to_csv(shap_csv_path, index=False)\n",
        "        exp.log_artifact(shap_csv_path)\n",
        "        \n",
        "        # =====================================================\n",
        "        # SHAP Summary Plotã‚’ç”»åƒã¨ã—ã¦ä¿å­˜ãƒ»ã‚¢ãƒ¼ãƒ†ã‚£ãƒ•ã‚¡ã‚¯ãƒˆè¨˜éŒ²\n",
        "        # =====================================================\n",
        "        plt.figure(figsize=(10, 6))\n",
        "        shap.summary_plot(shap_values, X_test, feature_names=FEATURE_COLS, show=False)\n",
        "        plt.title(f\"SHAP Summary Plot - {display_name}\")\n",
        "        plt.tight_layout()\n",
        "        \n",
        "        # ç”»åƒã‚’ä¿å­˜\n",
        "        shap_plot_path = f\"/tmp/shap_summary_{display_name}.png\"\n",
        "        plt.savefig(shap_plot_path, bbox_inches='tight', dpi=150)\n",
        "        plt.close()\n",
        "        \n",
        "        # ã‚¢ãƒ¼ãƒ†ã‚£ãƒ•ã‚¡ã‚¯ãƒˆã¨ã—ã¦è¨˜éŒ²\n",
        "        exp.log_artifact(shap_plot_path)\n",
        "        print(f\"\\n  ğŸ“¸ ã‚¢ãƒ¼ãƒ†ã‚£ãƒ•ã‚¡ã‚¯ãƒˆä¿å­˜:\")\n",
        "        print(f\"    - {cm_plot_path}\")\n",
        "        print(f\"    - {fi_plot_path}\")\n",
        "        print(f\"    - {shap_csv_path} (å®Œå…¨ãƒ‡ãƒ¼ã‚¿)\")\n",
        "        print(f\"    - {shap_plot_path}\")\n",
        "        \n",
        "        # çµæœã‚’ä¿å­˜\n",
        "        results.append({\n",
        "            \"run_name\": display_name,\n",
        "            \"accuracy\": accuracy,\n",
        "            \"precision\": precision,\n",
        "            \"recall\": recall,\n",
        "            \"f1_score\": f1,\n",
        "            \"roc_auc\": roc_auc,\n",
        "            \"training_time\": training_time,\n",
        "            \"confusion_matrix\": {\"tn\": int(tn), \"fp\": int(fp), \"fn\": int(fn), \"tp\": int(tp)},\n",
        "            \"model\": model,\n",
        "            \"params\": params,\n",
        "            \"feature_importance\": importance_dict,\n",
        "            \"shap_importance\": shap_dict,\n",
        "            \"shap_values\": shap_values\n",
        "        })\n",
        "        \n",
        "        print(f\"\\n  âœ… ãƒ¡ãƒˆãƒªã‚¯ã‚¹:\")\n",
        "        print(f\"    Accuracy:  {accuracy:.4f}\")\n",
        "        print(f\"    Precision: {precision:.4f}\")\n",
        "        print(f\"    Recall:    {recall:.4f}\")\n",
        "        print(f\"    F1 Score:  {f1:.4f}\")\n",
        "        print(f\"    ROC-AUC:   {roc_auc:.4f}\")\n",
        "        print(f\"    å­¦ç¿’æ™‚é–“:  {training_time:.2f}ç§’\")\n",
        "\n",
        "print(f\"\\nâœ… {len(experiments)}ã¤ã®å®Ÿé¨“ãŒå®Œäº†ã—ã¾ã—ãŸ\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "14e44461",
      "metadata": {},
      "source": [
        "---\n",
        "## 4.5 å®Ÿé¨“çµæœã®æ¯”è¼ƒ\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ffbf800c",
      "metadata": {},
      "outputs": [],
      "source": [
        "# çµæœã‚’DataFrameã§æ¯”è¼ƒ\n",
        "results_df = pd.DataFrame([{\n",
        "    \"Run\": r[\"run_name\"],\n",
        "    \"Accuracy\": f\"{r['accuracy']:.4f}\",\n",
        "    \"Precision\": f\"{r['precision']:.4f}\",\n",
        "    \"Recall\": f\"{r['recall']:.4f}\",\n",
        "    \"F1 Score\": f\"{r['f1_score']:.4f}\",\n",
        "    \"ROC-AUC\": f\"{r['roc_auc']:.4f}\",\n",
        "    \"Time(s)\": f\"{r['training_time']:.2f}\"\n",
        "} for r in results])\n",
        "\n",
        "print(\"=\" * 90)\n",
        "print(\"ğŸ“Š å®Ÿé¨“çµæœã®æ¯”è¼ƒ\")\n",
        "print(\"=\" * 90)\n",
        "print(results_df.to_string(index=False))\n",
        "print(\"=\" * 90)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e5c82a16",
      "metadata": {},
      "outputs": [],
      "source": [
        "# æœ€è‰¯ãƒ¢ãƒ‡ãƒ«ã®é¸æŠï¼ˆF1ã‚¹ã‚³ã‚¢åŸºæº–ï¼‰\n",
        "best_result = max(results, key=lambda x: x[\"f1_score\"])\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"ğŸ† æœ€è‰¯ãƒ¢ãƒ‡ãƒ«ï¼ˆF1ã‚¹ã‚³ã‚¢åŸºæº–ï¼‰\")\n",
        "print(\"=\" * 60)\n",
        "print(f\"  Run Name:  {best_result['run_name']}\")\n",
        "print(f\"  F1 Score:  {best_result['f1_score']:.4f}\")\n",
        "print(f\"  ROC-AUC:   {best_result['roc_auc']:.4f}\")\n",
        "print(f\"  Accuracy:  {best_result['accuracy']:.4f}\")\n",
        "print(f\"  Precision: {best_result['precision']:.4f}\")\n",
        "print(f\"  Recall:    {best_result['recall']:.4f}\")\n",
        "print(f\"  å­¦ç¿’æ™‚é–“:  {best_result['training_time']:.2f}ç§’\")\n",
        "print(\"=\"  * 60)\n",
        "print(f\"  ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿: {best_result['params']}\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Confusion Matrixã®çµæœã‚’è¡¨ç¤º\n",
        "cm = best_result['confusion_matrix']\n",
        "print(f\"\\nğŸ“Š Confusion Matrix:\")\n",
        "print(f\"  True Negatives:  {cm['tn']:,}\")\n",
        "print(f\"  False Positives: {cm['fp']:,}\")\n",
        "print(f\"  False Negatives: {cm['fn']:,}\")\n",
        "print(f\"  True Positives:  {cm['tp']:,}\")\n",
        "\n",
        "# æœ€è‰¯ãƒ¢ãƒ‡ãƒ«ã®ç‰¹å¾´é‡é‡è¦åº¦ã‚’è¡¨ç¤º\n",
        "print(\"\\nğŸ“Š æœ€è‰¯ãƒ¢ãƒ‡ãƒ«ã®ç‰¹å¾´é‡é‡è¦åº¦ï¼ˆä¸Šä½5ä»¶ï¼‰:\")\n",
        "sorted_importance = sorted(best_result['feature_importance'].items(), key=lambda x: x[1], reverse=True)\n",
        "for feat, imp in sorted_importance[:5]:\n",
        "    print(f\"  {feat}: {imp:.4f}\")\n",
        "\n",
        "print(\"\\nğŸ” æœ€è‰¯ãƒ¢ãƒ‡ãƒ«ã®SHAPå€¤ï¼ˆä¸Šä½5ä»¶ï¼‰:\")\n",
        "sorted_shap = sorted(best_result['shap_importance'].items(), key=lambda x: x[1], reverse=True)\n",
        "for feat, shap_val in sorted_shap[:5]:\n",
        "    print(f\"  {feat}: {shap_val:.4f}\")\n",
        "\n",
        "# æœ€è‰¯ãƒ¢ãƒ‡ãƒ«ã‚’ä¿å­˜\n",
        "best_model = best_result[\"model\"]\n",
        "best_metrics = {\n",
        "    \"accuracy\": best_result[\"accuracy\"],\n",
        "    \"precision\": best_result[\"precision\"],\n",
        "    \"recall\": best_result[\"recall\"],\n",
        "    \"f1_score\": best_result[\"f1_score\"],\n",
        "    \"roc_auc\": best_result[\"roc_auc\"]\n",
        "}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "73a86440",
      "metadata": {},
      "source": [
        "---\n",
        "## 4.6 å¯è¦–åŒ–\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5440ece9",
      "metadata": {},
      "outputs": [],
      "source": [
        "# å®Ÿé¨“çµæœã®ãƒãƒ¼ãƒãƒ£ãƒ¼ãƒˆï¼ˆãƒ¡ãƒˆãƒªã‚¯ã‚¹ï¼‰\n",
        "metrics_to_plot = [\"accuracy\", \"precision\", \"recall\", \"f1_score\", \"roc_auc\"]\n",
        "run_names = [r[\"run_name\"] for r in results]\n",
        "\n",
        "fig, axes = plt.subplots(1, 5, figsize=(16, 4))\n",
        "\n",
        "for i, metric in enumerate(metrics_to_plot):\n",
        "    values = [r[metric] for r in results]\n",
        "    colors = ['gold' if r[\"run_name\"] == best_result[\"run_name\"] else 'steelblue' for r in results]\n",
        "    axes[i].bar(run_names, values, color=colors)\n",
        "    axes[i].set_title(metric.replace('_', ' ').title())\n",
        "    axes[i].set_ylim(0, 1)\n",
        "    axes[i].tick_params(axis='x', rotation=45)\n",
        "\n",
        "plt.suptitle('Experiment Results Comparison - Metrics', fontsize=14, fontweight='bold')\n",
        "plt.tight_layout()\n",
        "\n",
        "# ğŸ†• ãƒ¡ãƒˆãƒªã‚¯ã‚¹æ¯”è¼ƒãƒãƒ£ãƒ¼ãƒˆã‚’ã‚¢ãƒ¼ãƒ†ã‚£ãƒ•ã‚¡ã‚¯ãƒˆã¨ã—ã¦ä¿å­˜\n",
        "metrics_comparison_path = f\"/tmp/metrics_comparison_{timestamp}.png\"\n",
        "plt.savefig(metrics_comparison_path, bbox_inches='tight', dpi=150)\n",
        "plt.show()\n",
        "\n",
        "# å®Ÿè¡Œæ™‚é–“ã®æ¯”è¼ƒ\n",
        "fig, ax = plt.subplots(figsize=(8, 4))\n",
        "times = [r[\"training_time\"] for r in results]\n",
        "colors = ['gold' if r[\"run_name\"] == best_result[\"run_name\"] else 'steelblue' for r in results]\n",
        "ax.bar(run_names, times, color=colors)\n",
        "ax.set_title('Training Time Comparison', fontsize=14, fontweight='bold')\n",
        "ax.set_ylabel('Time (seconds)')\n",
        "ax.tick_params(axis='x', rotation=45)\n",
        "for i, t in enumerate(times):\n",
        "    ax.annotate(f'{t:.2f}s', (i, t), ha='center', va='bottom')\n",
        "plt.tight_layout()\n",
        "\n",
        "# ğŸ†• å®Ÿè¡Œæ™‚é–“æ¯”è¼ƒãƒãƒ£ãƒ¼ãƒˆã‚’ã‚¢ãƒ¼ãƒ†ã‚£ãƒ•ã‚¡ã‚¯ãƒˆã¨ã—ã¦ä¿å­˜\n",
        "time_comparison_path = f\"/tmp/training_time_comparison_{timestamp}.png\"\n",
        "plt.savefig(time_comparison_path, bbox_inches='tight', dpi=150)\n",
        "plt.show()\n",
        "\n",
        "# ğŸ†• å®Ÿé¨“å…¨ä½“ã®æ¯”è¼ƒç”»åƒã‚’ã‚¢ãƒ¼ãƒ†ã‚£ãƒ•ã‚¡ã‚¯ãƒˆã¨ã—ã¦è¨˜éŒ²\n",
        "print(\"ğŸ“¸ å®Ÿé¨“æ¯”è¼ƒãƒãƒ£ãƒ¼ãƒˆã‚’ä¿å­˜ã—ã¾ã—ãŸ:\")\n",
        "print(f\"   - {metrics_comparison_path}\")\n",
        "print(f\"   - {time_comparison_path}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "339361c0",
      "metadata": {},
      "outputs": [],
      "source": [
        "# æœ€è‰¯ãƒ¢ãƒ‡ãƒ«ã®SHAP Summary Plotã‚’è¡¨ç¤º\n",
        "print(f\"=== ğŸ” æœ€è‰¯ãƒ¢ãƒ‡ãƒ«ï¼ˆ{best_result['run_name']}ï¼‰ã®SHAP Summary Plot ===\")\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "shap.summary_plot(\n",
        "    best_result['shap_values'], \n",
        "    X_test, \n",
        "    feature_names=FEATURE_COLS,\n",
        "    show=False\n",
        ")\n",
        "plt.title(f\"SHAP Summary Plot - {best_result['run_name']}\", fontsize=14, fontweight='bold')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nğŸ’¡ ã“ã®ãƒ—ãƒ­ãƒƒãƒˆã®è¦‹æ–¹:\")\n",
        "print(\"   - æ¨ªè»¸: SHAPå€¤ï¼ˆäºˆæ¸¬ã¸ã®å½±éŸ¿åº¦ï¼‰\")\n",
        "print(\"   - ç¸¦è»¸: ç‰¹å¾´é‡ï¼ˆé‡è¦åº¦é †ï¼‰\")\n",
        "print(\"   - è‰²: ç‰¹å¾´é‡ã®å€¤ï¼ˆèµ¤=é«˜ã€é’=ä½ï¼‰\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a74c40ae",
      "metadata": {},
      "source": [
        "---\n",
        "## 4.7 å®Ÿé¨“çµæœã®æ°¸ç¶šåŒ–\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "49d3f1bc",
      "metadata": {},
      "outputs": [],
      "source": [
        "# å®Ÿé¨“çµæœã‚’ãƒ†ãƒ¼ãƒ–ãƒ«ã«ä¿å­˜ï¼ˆè£œåŠ©çš„ãªè¨˜éŒ²ï¼‰\n",
        "import datetime\n",
        "\n",
        "experiment_records = []\n",
        "for r in results:\n",
        "    experiment_records.append({\n",
        "        \"EXPERIMENT_NAME\": EXPERIMENT_NAME,\n",
        "        \"RUN_NAME\": r[\"run_name\"],\n",
        "        \"ACCURACY\": r[\"accuracy\"],\n",
        "        \"PRECISION\": r[\"precision\"],\n",
        "        \"RECALL\": r[\"recall\"],\n",
        "        \"F1_SCORE\": r[\"f1_score\"],\n",
        "        \"ROC_AUC\": r[\"roc_auc\"],                                    # ğŸ†• ROC-AUC\n",
        "        \"TRAINING_TIME_SEC\": r[\"training_time\"],                    # ğŸ†• å®Ÿè¡Œæ™‚é–“\n",
        "        \"CONFUSION_MATRIX\": json.dumps(r[\"confusion_matrix\"]),      # ğŸ†• Confusion Matrix\n",
        "        \"PARAMS\": json.dumps(r[\"params\"]),\n",
        "        \"FEATURE_IMPORTANCE\": json.dumps(r[\"feature_importance\"]),\n",
        "        \"SHAP_IMPORTANCE\": json.dumps(r[\"shap_importance\"]),\n",
        "        \"DATASET_INFO\": json.dumps(dataset_info),                   # ğŸ†• ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆæƒ…å ±\n",
        "        \"CREATED_AT\": datetime.datetime.now().isoformat()\n",
        "    })\n",
        "\n",
        "records_df = session.create_dataframe(experiment_records)\n",
        "records_df.write.save_as_table(\n",
        "    \"MLOPS_HOL_DB.FEATURE_STORE.EXPERIMENT_RESULTS\",\n",
        "    mode=\"overwrite\"\n",
        ")\n",
        "\n",
        "print(\"âœ… å®Ÿé¨“çµæœã‚’ãƒ†ãƒ¼ãƒ–ãƒ«ã«ä¿å­˜ã—ã¾ã—ãŸ\")\n",
        "print(\"   ãƒ†ãƒ¼ãƒ–ãƒ«: MLOPS_HOL_DB.FEATURE_STORE.EXPERIMENT_RESULTS\")\n",
        "print(\"\\nğŸ“ ä¿å­˜ã•ã‚ŒãŸé …ç›®:\")\n",
        "print(\"   - ãƒ¡ãƒˆãƒªã‚¯ã‚¹ï¼ˆAccuracy, Precision, Recall, F1, ROC-AUCï¼‰\")\n",
        "print(\"   - å®Ÿè¡Œæ™‚é–“\")\n",
        "print(\"   - Confusion Matrixï¼ˆJSONï¼‰\")\n",
        "print(\"   - ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼ˆJSONï¼‰\")\n",
        "print(\"   - ç‰¹å¾´é‡é‡è¦åº¦ï¼ˆJSONï¼‰\")\n",
        "print(\"   - SHAPå€¤ï¼ˆJSONï¼‰\")\n",
        "print(\"   - ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆæƒ…å ±ï¼ˆJSONï¼‰\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fa974274",
      "metadata": {},
      "source": [
        "---\n",
        "## 4.7.1 Model Registryã¨ã®é€£æº\n",
        "\n",
        "æœ€è‰¯ãƒ¢ãƒ‡ãƒ«ã‚’ **Experiment TrackingçµŒç”±ã§** Model Registryã«ç™»éŒ²ã—ã¾ã™ã€‚\n",
        "ã“ã‚Œã«ã‚ˆã‚Šã€**å®Ÿé¨“ãƒ©ãƒ³ â†” ãƒ¢ãƒ‡ãƒ«ãƒãƒ¼ã‚¸ãƒ§ãƒ³** ãŒãƒªãƒ³ã‚¯ã•ã‚Œã€å®Œå…¨ãªè¿½è·¡å¯èƒ½æ€§ï¼ˆTraceabilityï¼‰ã‚’å®Ÿç¾ã§ãã¾ã™ã€‚\n",
        "\n",
        "### ğŸ’¡ MLOpsã®æœ¬è³ª\n",
        "- ã€Œã“ã®ãƒ¢ãƒ‡ãƒ«ã¯ã©ã®å®Ÿé¨“ã‹ã‚‰æ¥ãŸã®ã‹ï¼Ÿã€ãŒä¸€ç›®ã§åˆ†ã‹ã‚‹\n",
        "- å®Ÿé¨“ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒ»ãƒ¡ãƒˆãƒªã‚¯ã‚¹ãƒ»ã‚¢ãƒ¼ãƒ†ã‚£ãƒ•ã‚¡ã‚¯ãƒˆã¨ãƒ¢ãƒ‡ãƒ«ãŒç´ä»˜ã\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "642a27be",
      "metadata": {},
      "outputs": [],
      "source": [
        "# æœ€è‰¯ãƒ¢ãƒ‡ãƒ«ã‚’Model Registryã«ç™»éŒ²ï¼ˆå®Ÿé¨“ãƒ©ãƒ³ã¨ãƒªãƒ³ã‚¯ï¼‰\n",
        "MODEL_NAME = \"CUSTOMER_CHURN_PREDICTOR\"\n",
        "VERSION_NAME = \"v1\"\n",
        "\n",
        "print(f\"=== ğŸ”— æœ€è‰¯ãƒ¢ãƒ‡ãƒ«ã‚’Model Registryã«ç™»éŒ² ===\")\n",
        "print(f\"ãƒ¢ãƒ‡ãƒ«å: {MODEL_NAME}\")\n",
        "print(f\"ãƒãƒ¼ã‚¸ãƒ§ãƒ³: {VERSION_NAME}\")\n",
        "print(f\"å…ƒã®å®Ÿé¨“Run: {best_result['run_name']}\")\n",
        "\n",
        "# Model Registryã«æ¥ç¶š\n",
        "from snowflake.ml.registry import Registry\n",
        "registry = Registry(\n",
        "    session=session,\n",
        "    database_name=\"MLOPS_HOL_DB\",\n",
        "    schema_name=\"MODEL_REGISTRY\"\n",
        ")\n",
        "\n",
        "# æ—¢å­˜ã®v1ãŒã‚ã‚Œã°å‰Šé™¤ï¼ˆå†å®Ÿè¡Œå¯¾å¿œï¼‰\n",
        "try:\n",
        "    model = registry.get_model(MODEL_NAME)\n",
        "    versions = [v.version_name for v in model.versions()]\n",
        "    if VERSION_NAME in versions:\n",
        "        print(f\"\\nğŸ”„ æ—¢å­˜ã® {VERSION_NAME} ã‚’å‰Šé™¤ã—ã¦å†ç™»éŒ²ã—ã¾ã™...\")\n",
        "        model.delete_version(VERSION_NAME)\n",
        "except:\n",
        "    pass  # ãƒ¢ãƒ‡ãƒ«ãŒå­˜åœ¨ã—ãªã„å ´åˆã¯ä½•ã‚‚ã—ãªã„\n",
        "\n",
        "# æ–°ã—ã„ãƒ©ãƒ³ã‚’é–‹å§‹ã—ã€ãã®ä¸­ã§ãƒ¢ãƒ‡ãƒ«ã‚’ç™»éŒ²\n",
        "best_model_run_name = f\"BestModel_{timestamp}\"\n",
        "\n",
        "with exp.start_run(run_name=best_model_run_name):\n",
        "    # æœ€è‰¯ãƒ¢ãƒ‡ãƒ«ã®æƒ…å ±ã‚’ãƒ­ã‚°\n",
        "    exp.log_param(\"source_run\", best_result['run_name'])\n",
        "    exp.log_param(\"model_name\", MODEL_NAME)\n",
        "    exp.log_param(\"version\", VERSION_NAME)\n",
        "    \n",
        "    # æœ€è‰¯ãƒ¢ãƒ‡ãƒ«ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’å†ãƒ­ã‚°\n",
        "    for param_name, param_value in best_result['params'].items():\n",
        "        exp.log_param(param_name, param_value)\n",
        "    \n",
        "    # æœ€è‰¯ãƒ¢ãƒ‡ãƒ«ã®ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’å†ãƒ­ã‚°\n",
        "    exp.log_metric(\"accuracy\", best_result['accuracy'])\n",
        "    exp.log_metric(\"precision\", best_result['precision'])\n",
        "    exp.log_metric(\"recall\", best_result['recall'])\n",
        "    exp.log_metric(\"f1_score\", best_result['f1_score'])\n",
        "    exp.log_metric(\"roc_auc\", best_result['roc_auc'])\n",
        "    \n",
        "    # ğŸ”— Model Registryã«ç™»éŒ²ï¼ˆå®Ÿé¨“ãƒ©ãƒ³ã¨ãƒªãƒ³ã‚¯ï¼‰\n",
        "    exp.log_model(\n",
        "        model=best_model,\n",
        "        model_name=MODEL_NAME,\n",
        "        version_name=VERSION_NAME,\n",
        "        sample_input_data=X_train.head(10),  # å…¥åŠ›å½¢å¼ã®ã‚µãƒ³ãƒ—ãƒ«\n",
        "        metrics=best_metrics,\n",
        "        comment=f\"\"\"ãƒãƒ£ãƒ¼ãƒ³äºˆæ¸¬ãƒ¢ãƒ‡ãƒ« - Experiment Trackingé€£æºç‰ˆ\n",
        "\n",
        "ã€Lineageï¼ˆç³»è­œï¼‰æƒ…å ±ã€‘\n",
        "- å®Ÿé¨“å: {EXPERIMENT_NAME}\n",
        "- å…ƒã®Run: {best_result['run_name']}\n",
        "- ç™»éŒ²Run: {best_model_run_name}\n",
        "\n",
        "ã€ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã€‘\n",
        "{best_result['params']}\n",
        "\n",
        "ã€ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã€‘\n",
        "- F1 Score: {best_result['f1_score']:.4f}\n",
        "- ROC-AUC: {best_result['roc_auc']:.4f}\n",
        "\n",
        "ã€ç‰¹å¾´é‡ï¼ˆ{len(FEATURE_COLS)}å€‹ï¼‰ã€‘\n",
        "{', '.join(FEATURE_COLS)}\"\"\"\n",
        "    )\n",
        "\n",
        "print(f\"\\nâœ… Model Registryã«ç™»éŒ²å®Œäº†ï¼\")\n",
        "print(f\"   ãƒ¢ãƒ‡ãƒ«: {MODEL_NAME}\")\n",
        "print(f\"   ãƒãƒ¼ã‚¸ãƒ§ãƒ³: {VERSION_NAME}\")\n",
        "print(f\"   ãƒªãƒ³ã‚¯ã•ã‚ŒãŸRun: {best_model_run_name}\")\n",
        "print(f\"\\nğŸ”— Snowsight â†’ AI & ML â†’ Experiments ã§ç¢ºèªã™ã‚‹ã¨ã€\")\n",
        "print(f\"   ã€Œãƒ¢ãƒ‡ãƒ«ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã€ã«ãƒªãƒ³ã‚¯ãŒè¡¨ç¤ºã•ã‚Œã¾ã™ï¼\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9184b483",
      "metadata": {},
      "source": [
        "---\n",
        "## 4.8 å¾Œã‹ã‚‰æŒ¯ã‚Šè¿”ã‚‹æ–¹æ³•ï¼ˆã‚¢ãƒ¼ãƒ†ã‚£ãƒ•ã‚¡ã‚¯ãƒˆã®å–ã‚Šå‡ºã—ï¼‰\n",
        "\n",
        "Experiment Trackingã«ä¿å­˜ã—ãŸã‚¢ãƒ¼ãƒ†ã‚£ãƒ•ã‚¡ã‚¯ãƒˆï¼ˆç”»åƒã‚„CSVï¼‰ã¯ã€å¾Œã‹ã‚‰ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã§å–ã‚Šå‡ºã›ã¾ã™ã€‚\n",
        "\n",
        "### ğŸ’¡ ãƒ¦ãƒ¼ã‚¹ã‚±ãƒ¼ã‚¹\n",
        "- ã€Œ3ãƒ¶æœˆå‰ã®ãƒ¢ãƒ‡ãƒ«ã€ãªãœã“ã®äºˆæ¸¬ã‚’ã—ãŸã‚“ã ã£ã‘ï¼Ÿã€\n",
        "- ã€Œéå»ã®å®Ÿé¨“ã®SHAPå€¤ã‚’å†åˆ†æã—ãŸã„ã€\n",
        "- ã€Œç›£æŸ»ã®ãŸã‚ã«å½“æ™‚ã®ãƒ¢ãƒ‡ãƒ«è§£é‡ˆæƒ…å ±ã‚’æå‡ºã—ãŸã„ã€\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d3e7b944",
      "metadata": {},
      "outputs": [],
      "source": [
        "# éå»ã®å®Ÿé¨“ã‹ã‚‰ã‚¢ãƒ¼ãƒ†ã‚£ãƒ•ã‚¡ã‚¯ãƒˆã‚’å–ã‚Šå‡ºã™ä¾‹\n",
        "# â€» å®Ÿéš›ã«æŒ¯ã‚Šè¿”ã‚‹éš›ã¯ã€run_name ã‚’éå»ã®å®Ÿé¨“åã«å¤‰æ›´ã—ã¦ãã ã•ã„\n",
        "\n",
        "# ä»Šå›ã®å®Ÿé¨“ã®run_nameã‚’ä½¿ç”¨ï¼ˆä¾‹ã¨ã—ã¦æœ€åˆã®Baselineï¼‰\n",
        "example_run_name = experiments[0][\"run_name\"]\n",
        "\n",
        "print(f\"=== ğŸ“‚ ã‚¢ãƒ¼ãƒ†ã‚£ãƒ•ã‚¡ã‚¯ãƒˆä¸€è¦§ã®ç¢ºèª ===\")\n",
        "print(f\"Run: {example_run_name}\\n\")\n",
        "\n",
        "# ã‚¢ãƒ¼ãƒ†ã‚£ãƒ•ã‚¡ã‚¯ãƒˆä¸€è¦§ã‚’å–å¾—\n",
        "artifacts = exp.list_artifacts(run_name=example_run_name)\n",
        "print(\"ä¿å­˜ã•ã‚Œã¦ã„ã‚‹ã‚¢ãƒ¼ãƒ†ã‚£ãƒ•ã‚¡ã‚¯ãƒˆ:\")\n",
        "for artifact in artifacts:\n",
        "    print(f\"  - {artifact}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ce85f13e",
      "metadata": {},
      "outputs": [],
      "source": [
        "# SHAPå®Œå…¨ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã¦Summary Plotã‚’å†ç¾\n",
        "print(f\"=== ğŸ” SHAP Summary Plotã®å†ç¾ ===\")\n",
        "print(f\"Run: {example_run_name}\\n\")\n",
        "\n",
        "# ã‚¢ãƒ¼ãƒ†ã‚£ãƒ•ã‚¡ã‚¯ãƒˆã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰\n",
        "shap_artifact_name = \"shap_full_data_Baseline.csv\"\n",
        "local_download_path = \"/tmp/downloaded_shap/\"\n",
        "\n",
        "import os\n",
        "os.makedirs(local_download_path, exist_ok=True)\n",
        "\n",
        "# â€» ãƒ¡ã‚½ãƒƒãƒ‰åã¯ download_artifactsï¼ˆè¤‡æ•°å½¢ï¼‰ã€å¼•æ•°ã¯ target_path\n",
        "exp.download_artifacts(\n",
        "    run_name=example_run_name,\n",
        "    artifact_path=shap_artifact_name,\n",
        "    target_path=local_download_path\n",
        ")\n",
        "\n",
        "print(f\"âœ… ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å®Œäº†: {local_download_path}{shap_artifact_name}\")\n",
        "\n",
        "# CSVã‚’èª­ã¿è¾¼ã¿\n",
        "downloaded_shap_df = pd.read_csv(f\"{local_download_path}{shap_artifact_name}\")\n",
        "print(f\"   ãƒ‡ãƒ¼ã‚¿å½¢çŠ¶: {downloaded_shap_df.shape}\")\n",
        "\n",
        "# SHAPå€¤ã¨ç‰¹å¾´é‡å€¤ã‚’åˆ†é›¢\n",
        "shap_cols = [f\"shap_{col}\" for col in FEATURE_COLS]\n",
        "value_cols = [f\"value_{col}\" for col in FEATURE_COLS]\n",
        "\n",
        "downloaded_shap_values = downloaded_shap_df[shap_cols].values\n",
        "downloaded_feature_values = downloaded_shap_df[value_cols].values\n",
        "\n",
        "# Summary Plotã‚’å†ç¾ï¼\n",
        "print(\"\\nğŸ“Š éå»ã®å®Ÿé¨“ã®SHAP Summary Plotã‚’å†ç¾:\")\n",
        "plt.figure(figsize=(10, 6))\n",
        "shap.summary_plot(\n",
        "    downloaded_shap_values, \n",
        "    downloaded_feature_values, \n",
        "    feature_names=FEATURE_COLS,\n",
        "    show=False\n",
        ")\n",
        "plt.title(f\"SHAP Summary Plot (å†ç¾) - {example_run_name}\", fontsize=14, fontweight='bold')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nâœ… éå»ã®å®Ÿé¨“ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰å®Œå…¨ã«å†ç¾ã§ãã¾ã—ãŸï¼\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c932a35a",
      "metadata": {},
      "source": [
        "---\n",
        "## âœ… Section 4 å®Œäº†ï¼\n",
        "\n",
        "### å­¦ã‚“ã ã“ã¨\n",
        "- **Snowflake ML ExperimentTracking** ã®ä½¿ã„æ–¹\n",
        "- `exp.set_experiment()` ã§å®Ÿé¨“ã‚’ä½œæˆ\n",
        "- `exp.start_run()` ã§ãƒ©ãƒ³ã‚’é–‹å§‹\n",
        "- `exp.log_param()`, `exp.log_metric()` ã§ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒ»ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’è¨˜éŒ²\n",
        "- è¤‡æ•°å®Ÿé¨“ã®æ¯”è¼ƒã¨æœ€è‰¯ãƒ¢ãƒ‡ãƒ«ã®é¸æŠ\n",
        "\n",
        "### ğŸ“ è¨˜éŒ²ã—ãŸæƒ…å ±\n",
        "\n",
        "| ãƒ¡ã‚½ãƒƒãƒ‰ | è¨˜éŒ²å†…å®¹ | ç”¨é€” |\n",
        "|---------|---------|------|\n",
        "| `log_param()` | ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ | ãƒ¢ãƒ‡ãƒ«è¨­å®šã®è¿½è·¡ |\n",
        "| `log_param()` | ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆæƒ…å ± | å†ç¾æ€§ã®ç¢ºä¿ |\n",
        "| `log_metric()` | Accuracy, Precision, Recall, F1 | åˆ†é¡æ€§èƒ½è©•ä¾¡ |\n",
        "| `log_metric()` | ROC-AUC | é–¾å€¤ã«ä¾å­˜ã—ãªã„æ€§èƒ½è©•ä¾¡ |\n",
        "| `log_metric()` | å®Ÿè¡Œæ™‚é–“ | ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æ¯”è¼ƒ |\n",
        "| `log_metric()` | Confusion Matrix (TN/FP/FN/TP) | èª¤åˆ†é¡ãƒ‘ã‚¿ãƒ¼ãƒ³åˆ†æ |\n",
        "| `log_metric()` | ç‰¹å¾´é‡é‡è¦åº¦ | ãƒ¢ãƒ‡ãƒ«è§£é‡ˆæ€§ |\n",
        "| `log_metric()` | SHAPå€¤ | äºˆæ¸¬æ ¹æ‹ ã®èª¬æ˜ |\n",
        "| `log_artifact()` | Confusion Matrixç”»åƒ | èª¤åˆ†é¡ãƒ‘ã‚¿ãƒ¼ãƒ³ã®å¯è¦–åŒ– |\n",
        "| `log_artifact()` | Feature Importanceæ£’ã‚°ãƒ©ãƒ• | ç‰¹å¾´é‡é‡è¦åº¦ã®å¯è¦–åŒ– |\n",
        "| `log_artifact()` | **SHAPå®Œå…¨ãƒ‡ãƒ¼ã‚¿ï¼ˆCSVï¼‰** | **å¾Œã‹ã‚‰Summary Plotå†ç¾** |\n",
        "| `log_artifact()` | SHAP Summary Plot | SHAPå€¤ã®å¯è¦–åŒ– |\n",
        "\n",
        "### ä½œæˆã—ãŸã‚‚ã®\n",
        "- Experiment: `CHURN_PREDICTION_EXPERIMENT`\n",
        "- 3ã¤ã®Run: Baseline, DeepTree, Conservative\n",
        "- å®Ÿé¨“çµæœãƒ†ãƒ¼ãƒ–ãƒ«: `EXPERIMENT_RESULTS`\n",
        "  - ãƒ¡ãƒˆãƒªã‚¯ã‚¹ï¼ˆAccuracy, Precision, Recall, F1, ROC-AUCï¼‰\n",
        "  - å®Ÿè¡Œæ™‚é–“\n",
        "  - Confusion Matrixï¼ˆJSONï¼‰\n",
        "  - ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼ˆJSONï¼‰\n",
        "  - ç‰¹å¾´é‡é‡è¦åº¦ï¼ˆJSONï¼‰\n",
        "  - SHAPå€¤ï¼ˆJSONï¼‰\n",
        "  - ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆæƒ…å ±ï¼ˆJSONï¼‰\n",
        "- ã‚¢ãƒ¼ãƒ†ã‚£ãƒ•ã‚¡ã‚¯ãƒˆï¼ˆå„ãƒ©ãƒ³ã«4ãƒ•ã‚¡ã‚¤ãƒ«ãšã¤ï¼‰\n",
        "  - `confusion_matrix_{Runå}.png` - æ··åŒè¡Œåˆ—\n",
        "  - `feature_importance_{Runå}.png` - ç‰¹å¾´é‡é‡è¦åº¦æ£’ã‚°ãƒ©ãƒ•\n",
        "  - `shap_full_data_{Runå}.csv` - **SHAPå®Œå…¨ãƒ‡ãƒ¼ã‚¿ï¼ˆå†ç¾ç”¨ï¼‰**\n",
        "  - `shap_summary_{Runå}.png` - SHAP Summary Plot\n",
        "\n",
        "### ğŸ’¡ å¾Œã‹ã‚‰æŒ¯ã‚Šè¿”ã‚‹ã¨ãã®ãƒã‚¤ãƒ³ãƒˆ\n",
        "\n",
        "**æ–¹æ³•1: SQLã§ãƒ¡ãƒˆãƒªã‚¯ã‚¹ãƒ»ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’ç¢ºèª**\n",
        "```sql\n",
        "SELECT \n",
        "    RUN_NAME, F1_SCORE, ROC_AUC, TRAINING_TIME_SEC,\n",
        "    FEATURE_IMPORTANCE, SHAP_IMPORTANCE\n",
        "FROM MLOPS_HOL_DB.FEATURE_STORE.EXPERIMENT_RESULTS\n",
        "ORDER BY F1_SCORE DESC;\n",
        "```\n",
        "\n",
        "**æ–¹æ³•2: Pythonã§ã‚¢ãƒ¼ãƒ†ã‚£ãƒ•ã‚¡ã‚¯ãƒˆã‚’å–ã‚Šå‡ºã—ã¦SHAPå†ç¾**\n",
        "```python\n",
        "# ã‚¢ãƒ¼ãƒ†ã‚£ãƒ•ã‚¡ã‚¯ãƒˆä¸€è¦§\n",
        "artifacts = exp.list_artifacts(run_name=\"éå»ã®run_name\")\n",
        "\n",
        "# SHAPå®Œå…¨ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ï¼ˆâ€» download_artifacts ã¯è¤‡æ•°å½¢ï¼‰\n",
        "exp.download_artifacts(run_name=\"éå»ã®run_name\", \n",
        "                       artifact_path=\"shap_full_data_Baseline.csv\",\n",
        "                       target_path=\"/tmp/\")\n",
        "\n",
        "# Summary Plotã‚’å†ç¾\n",
        "shap_df = pd.read_csv(\"/tmp/shap_full_data_Baseline.csv\")\n",
        "shap.summary_plot(shap_df[shap_cols].values, shap_df[value_cols].values)\n",
        "```\n",
        "\n",
        "### æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—\n",
        "**Section 5: Model Registry** ã§ã¯ã€æœ€è‰¯ãƒ¢ãƒ‡ãƒ«ã‚’ç™»éŒ²ã—ã€\n",
        "ãƒãƒ¼ã‚¸ãƒ§ãƒ³ç®¡ç†ã¨æœ¬ç•ªãƒ‡ãƒ—ãƒ­ã‚¤ã®æº–å‚™ã‚’è¡Œã„ã¾ã™ã€‚\n",
        "\n",
        "â¡ï¸ `05_MODEL_REGISTRY` Notebookã«é€²ã‚“ã§ãã ã•ã„\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
