{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Section 7: Experiment Viewerï¼ˆStreamlitã‚¢ãƒ—ãƒªï¼‰\n",
        "\n",
        "## ğŸ¯ ã“ã®ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã®ç›®æ¨™\n",
        "- **Streamlit in Snowflake** ã§å®Ÿé¨“çµæœã‚’é–²è¦§ã§ãã‚‹ã‚¢ãƒ—ãƒªã‚’ä½œæˆ\n",
        "- éå»ã®å®Ÿé¨“ã®SHAPç”»åƒã‚„ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’ç°¡å˜ã«ç¢ºèªã§ãã‚‹ã‚ˆã†ã«ã™ã‚‹\n",
        "\n",
        "## ğŸ“‹ ãªãœå¿…è¦ï¼Ÿ\n",
        "- Snowsight UIã§ã¯ã‚¢ãƒ¼ãƒ†ã‚£ãƒ•ã‚¡ã‚¯ãƒˆç”»åƒã‚’ç›´æ¥ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ã§ããªã„\n",
        "- éå»ã®å®Ÿé¨“ã‚’æŒ¯ã‚Šè¿”ã‚‹éš›ã«ã€æ¯å›ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã§ã‚³ãƒ¼ãƒ‰ã‚’æ›¸ãã®ã¯é¢å€’\n",
        "- â†’ **ãƒ¯ãƒ³ã‚¯ãƒªãƒƒã‚¯ã§éå»ã®å®Ÿé¨“ã‚’å¯è¦–åŒ–**ã§ãã‚‹ã‚¢ãƒ—ãƒªãŒã‚ã‚‹ã¨ä¾¿åˆ©ï¼\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ’¡ å®Œæˆã‚¤ãƒ¡ãƒ¼ã‚¸\n",
        "\n",
        "```\n",
        "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
        "â”‚  ğŸ”¬ Experiment Viewer                                   â”‚\n",
        "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
        "â”‚  å®Ÿé¨“å: [CHURN_PREDICTION_EXPERIMENT â–¼]                â”‚\n",
        "â”‚  Run:    [Baseline â–¼]                                   â”‚\n",
        "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
        "â”‚  ğŸ“Š ãƒ¡ãƒˆãƒªã‚¯ã‚¹                                          â”‚\n",
        "â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”                 â”‚\n",
        "â”‚  â”‚F1: 0.78â”‚AUC:0.85â”‚Acc:0.82â”‚Time:2s â”‚                 â”‚\n",
        "â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”˜                 â”‚\n",
        "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
        "â”‚  ğŸ–¼ï¸ ã‚¢ãƒ¼ãƒ†ã‚£ãƒ•ã‚¡ã‚¯ãƒˆ                                    â”‚\n",
        "â”‚  [Confusion Matrix] [Feature Importance] [SHAP Plot]   â”‚\n",
        "â”‚                                                         â”‚\n",
        "â”‚         (é¸æŠã—ãŸç”»åƒãŒã“ã“ã«è¡¨ç¤º)                       â”‚\n",
        "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## 7.1 Streamlitã‚¢ãƒ—ãƒªã®ä½œæˆæ‰‹é †\n",
        "\n",
        "### Step 1: Streamlit Appä½œæˆç”»é¢ã‚’é–‹ã\n",
        "\n",
        "1. Snowsightå·¦ãƒ¡ãƒ‹ãƒ¥ãƒ¼ â†’ **Projects** â†’ **Streamlit**\n",
        "2. å³ä¸Šã® **+ Streamlit App** ã‚’ã‚¯ãƒªãƒƒã‚¯\n",
        "\n",
        "### Step 2: ã‚¢ãƒ—ãƒªè¨­å®š\n",
        "\n",
        "| é …ç›® | å€¤ |\n",
        "|------|---|\n",
        "| App name | `EXPERIMENT_VIEWER` |\n",
        "| App location (Database) | `MLOPS_HOL_DB` |\n",
        "| App location (Schema) | `FEATURE_STORE` |\n",
        "| App warehouse | `MLOPS_HOL_ML_WH` |\n",
        "\n",
        "### Step 3: ã‚³ãƒ¼ãƒ‰ã‚’è²¼ã‚Šä»˜ã‘\n",
        "\n",
        "ä¸‹ã®ã‚»ãƒ«ã®ã‚³ãƒ¼ãƒ‰ã‚’ **å…¨ã¦** ã‚³ãƒ”ãƒ¼ã—ã¦ã€Streamlitã‚¨ãƒ‡ã‚£ã‚¿ã«è²¼ã‚Šä»˜ã‘ã¦ãã ã•ã„ã€‚\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "# ğŸ“‹ ä»¥ä¸‹ã®ã‚³ãƒ¼ãƒ‰ã‚’ã‚³ãƒ”ãƒ¼ã—ã¦Streamlit in Snowflakeã«è²¼ã‚Šä»˜ã‘\n",
        "# ============================================================\n",
        "\n",
        "streamlit_code = '''\n",
        "import streamlit as st\n",
        "from snowflake.snowpark.context import get_active_session\n",
        "from snowflake.ml.experiment import ExperimentTracking\n",
        "import pandas as pd\n",
        "import json\n",
        "import os\n",
        "\n",
        "# ãƒšãƒ¼ã‚¸è¨­å®š\n",
        "st.set_page_config(\n",
        "    page_title=\"Experiment Viewer\",\n",
        "    page_icon=\"ğŸ”¬\",\n",
        "    layout=\"wide\"\n",
        ")\n",
        "\n",
        "# ã‚»ãƒƒã‚·ãƒ§ãƒ³å–å¾—\n",
        "session = get_active_session()\n",
        "\n",
        "# ã‚¿ã‚¤ãƒˆãƒ«\n",
        "st.title(\"ğŸ”¬ Experiment Viewer\")\n",
        "st.markdown(\"éå»ã®å®Ÿé¨“çµæœã¨ã‚¢ãƒ¼ãƒ†ã‚£ãƒ•ã‚¡ã‚¯ãƒˆã‚’é–²è¦§ã§ãã¾ã™\")\n",
        "\n",
        "st.divider()\n",
        "\n",
        "# ============================================================\n",
        "# ã‚µã‚¤ãƒ‰ãƒãƒ¼: å®Ÿé¨“ãƒ»Runé¸æŠ\n",
        "# ============================================================\n",
        "with st.sidebar:\n",
        "    st.header(\"ğŸ“‚ å®Ÿé¨“ã®é¸æŠ\")\n",
        "    \n",
        "    # å®Ÿé¨“çµæœãƒ†ãƒ¼ãƒ–ãƒ«ã‹ã‚‰ãƒ‡ãƒ¼ã‚¿å–å¾—\n",
        "    @st.cache_data(ttl=60)\n",
        "    def load_experiment_data():\n",
        "        df = session.table(\"MLOPS_HOL_DB.FEATURE_STORE.EXPERIMENT_RESULTS\").to_pandas()\n",
        "        return df\n",
        "    \n",
        "    try:\n",
        "        exp_df = load_experiment_data()\n",
        "        \n",
        "        # å®Ÿé¨“åé¸æŠ\n",
        "        experiment_names = exp_df[\"EXPERIMENT_NAME\"].unique().tolist()\n",
        "        selected_experiment = st.selectbox(\n",
        "            \"å®Ÿé¨“å\",\n",
        "            experiment_names,\n",
        "            index=0\n",
        "        )\n",
        "        \n",
        "        # é¸æŠã—ãŸå®Ÿé¨“ã®Runã‚’ãƒ•ã‚£ãƒ«ã‚¿\n",
        "        filtered_df = exp_df[exp_df[\"EXPERIMENT_NAME\"] == selected_experiment]\n",
        "        run_names = filtered_df[\"RUN_NAME\"].tolist()\n",
        "        \n",
        "        # Runé¸æŠ\n",
        "        selected_run = st.selectbox(\n",
        "            \"Runå\",\n",
        "            run_names,\n",
        "            index=0\n",
        "        )\n",
        "        \n",
        "        # é¸æŠã—ãŸRunã®ãƒ‡ãƒ¼ã‚¿\n",
        "        run_data = filtered_df[filtered_df[\"RUN_NAME\"] == selected_run].iloc[0]\n",
        "        \n",
        "        st.success(f\"âœ… {selected_run} ã‚’é¸æŠä¸­\")\n",
        "        \n",
        "    except Exception as e:\n",
        "        st.error(f\"ãƒ‡ãƒ¼ã‚¿å–å¾—ã‚¨ãƒ©ãƒ¼: {e}\")\n",
        "        st.info(\"Section 4ã‚’å®Ÿè¡Œã—ã¦EXPERIMENT_RESULTSãƒ†ãƒ¼ãƒ–ãƒ«ã‚’ä½œæˆã—ã¦ãã ã•ã„\")\n",
        "        st.stop()\n",
        "\n",
        "# ============================================================\n",
        "# ãƒ¡ã‚¤ãƒ³ã‚¨ãƒªã‚¢: ãƒ¡ãƒˆãƒªã‚¯ã‚¹è¡¨ç¤º\n",
        "# ============================================================\n",
        "st.header(\"ğŸ“Š ãƒ¡ãƒˆãƒªã‚¯ã‚¹\")\n",
        "\n",
        "col1, col2, col3, col4, col5 = st.columns(5)\n",
        "\n",
        "with col1:\n",
        "    st.metric(\"F1 Score\", f\"{run_data['F1_SCORE']:.4f}\")\n",
        "with col2:\n",
        "    st.metric(\"ROC-AUC\", f\"{run_data['ROC_AUC']:.4f}\")\n",
        "with col3:\n",
        "    st.metric(\"Accuracy\", f\"{run_data['ACCURACY']:.4f}\")\n",
        "with col4:\n",
        "    st.metric(\"Precision\", f\"{run_data['PRECISION']:.4f}\")\n",
        "with col5:\n",
        "    st.metric(\"Recall\", f\"{run_data['RECALL']:.4f}\")\n",
        "\n",
        "# è¿½åŠ ãƒ¡ãƒˆãƒªã‚¯ã‚¹\n",
        "col6, col7 = st.columns(2)\n",
        "with col6:\n",
        "    st.metric(\"å­¦ç¿’æ™‚é–“\", f\"{run_data['TRAINING_TIME_SEC']:.2f} ç§’\")\n",
        "with col7:\n",
        "    cm = json.loads(run_data['CONFUSION_MATRIX'])\n",
        "    st.metric(\"True Positives\", f\"{cm['tp']:,}\")\n",
        "\n",
        "st.divider()\n",
        "\n",
        "# ============================================================\n",
        "# ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ & ç‰¹å¾´é‡é‡è¦åº¦\n",
        "# ============================================================\n",
        "col_left, col_right = st.columns(2)\n",
        "\n",
        "with col_left:\n",
        "    st.header(\"âš™ï¸ ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿\")\n",
        "    params = json.loads(run_data['PARAMS'])\n",
        "    st.json(params)\n",
        "\n",
        "with col_right:\n",
        "    st.header(\"ğŸ“ˆ ç‰¹å¾´é‡é‡è¦åº¦\")\n",
        "    importance = json.loads(run_data['FEATURE_IMPORTANCE'])\n",
        "    # é‡è¦åº¦é †ã«ã‚½ãƒ¼ãƒˆ\n",
        "    sorted_importance = dict(sorted(importance.items(), key=lambda x: x[1], reverse=True))\n",
        "    \n",
        "    # æ£’ã‚°ãƒ©ãƒ•ã§è¡¨ç¤º\n",
        "    import altair as alt\n",
        "    imp_df = pd.DataFrame({\n",
        "        \"Feature\": list(sorted_importance.keys()),\n",
        "        \"Importance\": list(sorted_importance.values())\n",
        "    })\n",
        "    chart = alt.Chart(imp_df).mark_bar().encode(\n",
        "        x=alt.X(\"Importance:Q\"),\n",
        "        y=alt.Y(\"Feature:N\", sort=\"-x\"),\n",
        "        color=alt.value(\"steelblue\")\n",
        "    ).properties(height=250)\n",
        "    st.altair_chart(chart, use_container_width=True)\n",
        "\n",
        "st.divider()\n",
        "\n",
        "# ============================================================\n",
        "# SHAPå€¤\n",
        "# ============================================================\n",
        "st.header(\"ğŸ” SHAPå€¤ï¼ˆå¹³å‡çµ¶å¯¾å€¤ï¼‰\")\n",
        "\n",
        "shap_importance = json.loads(run_data['SHAP_IMPORTANCE'])\n",
        "sorted_shap = dict(sorted(shap_importance.items(), key=lambda x: x[1], reverse=True))\n",
        "\n",
        "shap_df = pd.DataFrame({\n",
        "    \"Feature\": list(sorted_shap.keys()),\n",
        "    \"SHAP Value\": list(sorted_shap.values())\n",
        "})\n",
        "shap_chart = alt.Chart(shap_df).mark_bar().encode(\n",
        "    x=alt.X(\"SHAP Value:Q\"),\n",
        "    y=alt.Y(\"Feature:N\", sort=\"-x\"),\n",
        "    color=alt.value(\"coral\")\n",
        ").properties(height=250)\n",
        "st.altair_chart(shap_chart, use_container_width=True)\n",
        "\n",
        "st.divider()\n",
        "\n",
        "# ============================================================\n",
        "# ã‚¢ãƒ¼ãƒ†ã‚£ãƒ•ã‚¡ã‚¯ãƒˆç”»åƒã®è¡¨ç¤º\n",
        "# ============================================================\n",
        "st.header(\"ğŸ–¼ï¸ ã‚¢ãƒ¼ãƒ†ã‚£ãƒ•ã‚¡ã‚¯ãƒˆç”»åƒ\")\n",
        "\n",
        "# Experiment TrackingåˆæœŸåŒ–\n",
        "exp = ExperimentTracking(session=session)\n",
        "exp.set_experiment(selected_experiment)\n",
        "\n",
        "# ã‚¢ãƒ¼ãƒ†ã‚£ãƒ•ã‚¡ã‚¯ãƒˆä¸€è¦§å–å¾—\n",
        "try:\n",
        "    # Runåã‹ã‚‰display_nameã‚’æŠ½å‡ºï¼ˆBaseline_20251218_xxx â†’ Baselineï¼‰\n",
        "    display_name = selected_run.split(\"_\")[0]\n",
        "    \n",
        "    # ç”»åƒã‚¿ã‚¤ãƒ—é¸æŠ\n",
        "    image_type = st.radio(\n",
        "        \"è¡¨ç¤ºã™ã‚‹ç”»åƒ\",\n",
        "        [\"Confusion Matrix\", \"Feature Importance\", \"SHAP Summary Plot\"],\n",
        "        horizontal=True\n",
        "    )\n",
        "    \n",
        "    # å¯¾å¿œã™ã‚‹ãƒ•ã‚¡ã‚¤ãƒ«å\n",
        "    artifact_map = {\n",
        "        \"Confusion Matrix\": f\"confusion_matrix_{display_name}.png\",\n",
        "        \"Feature Importance\": f\"feature_importance_{display_name}.png\",\n",
        "        \"SHAP Summary Plot\": f\"shap_summary_{display_name}.png\"\n",
        "    }\n",
        "    \n",
        "    artifact_name = artifact_map[image_type]\n",
        "    \n",
        "    # ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å…ˆ\n",
        "    download_path = \"/tmp/experiment_viewer/\"\n",
        "    os.makedirs(download_path, exist_ok=True)\n",
        "    \n",
        "    # ãƒœã‚¿ãƒ³ã§ç”»åƒã‚’ãƒ­ãƒ¼ãƒ‰\n",
        "    if st.button(f\"ğŸ“¥ {image_type} ã‚’è¡¨ç¤º\", type=\"primary\"):\n",
        "        with st.spinner(\"ç”»åƒã‚’å–å¾—ä¸­...\"):\n",
        "            try:\n",
        "                exp.download_artifacts(\n",
        "                    run_name=selected_run,\n",
        "                    artifact_path=artifact_name,\n",
        "                    target_path=download_path\n",
        "                )\n",
        "                \n",
        "                image_path = f\"{download_path}{artifact_name}\"\n",
        "                \n",
        "                if os.path.exists(image_path):\n",
        "                    st.image(image_path, caption=f\"{image_type} - {selected_run}\")\n",
        "                    st.success(\"âœ… ç”»åƒã‚’è¡¨ç¤ºã—ã¾ã—ãŸ\")\n",
        "                else:\n",
        "                    st.warning(f\"ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {artifact_name}\")\n",
        "                    \n",
        "            except Exception as e:\n",
        "                st.error(f\"ç”»åƒå–å¾—ã‚¨ãƒ©ãƒ¼: {e}\")\n",
        "                st.info(\"ã‚¢ãƒ¼ãƒ†ã‚£ãƒ•ã‚¡ã‚¯ãƒˆãŒå­˜åœ¨ã—ãªã„å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™\")\n",
        "\n",
        "except Exception as e:\n",
        "    st.error(f\"ã‚¢ãƒ¼ãƒ†ã‚£ãƒ•ã‚¡ã‚¯ãƒˆå–å¾—ã‚¨ãƒ©ãƒ¼: {e}\")\n",
        "\n",
        "st.divider()\n",
        "\n",
        "# ============================================================\n",
        "# ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆæƒ…å ±\n",
        "# ============================================================\n",
        "with st.expander(\"ğŸ“‹ ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆæƒ…å ±\"):\n",
        "    dataset_info = json.loads(run_data['DATASET_INFO'])\n",
        "    col1, col2, col3 = st.columns(3)\n",
        "    with col1:\n",
        "        st.metric(\"ç·ã‚µãƒ³ãƒ—ãƒ«æ•°\", f\"{dataset_info['total_samples']:,}\")\n",
        "    with col2:\n",
        "        st.metric(\"è¨“ç·´ãƒ‡ãƒ¼ã‚¿\", f\"{dataset_info['train_samples']:,}\")\n",
        "    with col3:\n",
        "        st.metric(\"ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿\", f\"{dataset_info['test_samples']:,}\")\n",
        "    \n",
        "    st.write(f\"**ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆå**: {dataset_info['dataset_name']}\")\n",
        "    st.write(f\"**ç‰¹å¾´é‡æ•°**: {dataset_info['num_features']}\")\n",
        "    st.write(f\"**è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã®ãƒãƒ£ãƒ¼ãƒ³ç‡**: {dataset_info['train_churn_rate']:.1%}\")\n",
        "    st.write(f\"**ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã®ãƒãƒ£ãƒ¼ãƒ³ç‡**: {dataset_info['test_churn_rate']:.1%}\")\n",
        "\n",
        "# ãƒ•ãƒƒã‚¿ãƒ¼\n",
        "st.divider()\n",
        "st.caption(\"ğŸ”¬ MLOps Hands-on - Experiment Viewer | Powered by Streamlit in Snowflake\")\n",
        "'''\n",
        "\n",
        "print(\"=\" * 70)\n",
        "print(\"ğŸ“‹ ä»¥ä¸‹ã®ã‚³ãƒ¼ãƒ‰ã‚’Streamlit in Snowflakeã«ã‚³ãƒ”ãƒ¼ï¼†ãƒšãƒ¼ã‚¹ãƒˆã—ã¦ãã ã•ã„\")\n",
        "print(\"=\" * 70)\n",
        "print(streamlit_code)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## 7.2 ã‚¢ãƒ—ãƒªã®æ©Ÿèƒ½è§£èª¬\n",
        "\n",
        "### ğŸ“Š ãƒ¡ãƒˆãƒªã‚¯ã‚¹è¡¨ç¤º\n",
        "```python\n",
        "# EXPERIMENT_RESULTSãƒ†ãƒ¼ãƒ–ãƒ«ã‹ã‚‰å–å¾—\n",
        "st.metric(\"F1 Score\", f\"{run_data['F1_SCORE']:.4f}\")\n",
        "```\n",
        "- Section 4ã§ä¿å­˜ã—ãŸãƒ†ãƒ¼ãƒ–ãƒ«ã‹ã‚‰ç›´æ¥èª­ã¿è¾¼ã¿\n",
        "- ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã§æœ€æ–°ãƒ‡ãƒ¼ã‚¿ã‚’è¡¨ç¤º\n",
        "\n",
        "### ğŸ“ˆ ç‰¹å¾´é‡é‡è¦åº¦ã‚°ãƒ©ãƒ•\n",
        "```python\n",
        "# JSONã‚’ãƒ‘ãƒ¼ã‚¹ã—ã¦æ£’ã‚°ãƒ©ãƒ•åŒ–\n",
        "importance = json.loads(run_data['FEATURE_IMPORTANCE'])\n",
        "```\n",
        "- Altairã§å‹•çš„ãªã‚°ãƒ©ãƒ•ã‚’ç”Ÿæˆ\n",
        "- é‡è¦åº¦é †ã«ã‚½ãƒ¼ãƒˆã—ã¦è¡¨ç¤º\n",
        "\n",
        "### ğŸ–¼ï¸ ã‚¢ãƒ¼ãƒ†ã‚£ãƒ•ã‚¡ã‚¯ãƒˆç”»åƒ\n",
        "```python\n",
        "# Experiment Trackingã‹ã‚‰ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰\n",
        "exp.download_artifacts(\n",
        "    run_name=selected_run,\n",
        "    artifact_path=artifact_name,\n",
        "    target_path=download_path\n",
        ")\n",
        "st.image(image_path)\n",
        "```\n",
        "- ãƒœã‚¿ãƒ³ã‚¯ãƒªãƒƒã‚¯ã§ã‚ªãƒ³ãƒ‡ãƒãƒ³ãƒ‰ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰\n",
        "- å¿…è¦ãªç”»åƒã ã‘å–å¾—ã™ã‚‹ã®ã§è»½é‡\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## âœ… Section 7 å®Œäº†ï¼\n",
        "\n",
        "### å­¦ã‚“ã ã“ã¨\n",
        "- **Streamlit in Snowflake** ã§ã‚¢ãƒ—ãƒªã‚’ä½œæˆ\n",
        "- Experiment Trackingã®ãƒ‡ãƒ¼ã‚¿ã‚’å¯è¦–åŒ–\n",
        "- ã‚¢ãƒ¼ãƒ†ã‚£ãƒ•ã‚¡ã‚¯ãƒˆï¼ˆç”»åƒï¼‰ã‚’ã‚¢ãƒ—ãƒªå†…ã§è¡¨ç¤º\n",
        "\n",
        "### ä½œæˆã—ãŸã‚‚ã®\n",
        "- Streamlit App: `EXPERIMENT_VIEWER`\n",
        "  - å®Ÿé¨“ãƒ»Runé¸æŠæ©Ÿèƒ½\n",
        "  - ãƒ¡ãƒˆãƒªã‚¯ã‚¹è¡¨ç¤ºï¼ˆF1, AUC, Accuracyç­‰ï¼‰\n",
        "  - ç‰¹å¾´é‡é‡è¦åº¦ã‚°ãƒ©ãƒ•\n",
        "  - SHAPå€¤ã‚°ãƒ©ãƒ•\n",
        "  - ã‚¢ãƒ¼ãƒ†ã‚£ãƒ•ã‚¡ã‚¯ãƒˆç”»åƒè¡¨ç¤º\n",
        "\n",
        "### ğŸ’¡ æ´»ç”¨ã‚·ãƒ¼ãƒ³\n",
        "- **å®Ÿé¨“ãƒ¬ãƒ“ãƒ¥ãƒ¼**: éå»ã®å®Ÿé¨“çµæœã‚’ãƒãƒ¼ãƒ ã§å…±æœ‰\n",
        "- **ãƒ¢ãƒ‡ãƒ«é¸å®š**: è¤‡æ•°ãƒ¢ãƒ‡ãƒ«ã®æ¯”è¼ƒæ¤œè¨\n",
        "- **ç›£æŸ»å¯¾å¿œ**: ãƒ¢ãƒ‡ãƒ«ã®èª¬æ˜è²¬ä»»ã‚’æœãŸã™\n",
        "- **ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ**: ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚·ãƒ§ãƒƒãƒˆã§ãƒ¬ãƒãƒ¼ãƒˆä½œæˆ\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ‰ ãƒãƒ³ã‚ºã‚ªãƒ³å®Œäº†ï¼\n",
        "\n",
        "ãŠç–²ã‚Œã•ã¾ã§ã—ãŸï¼ä»¥ä¸‹ã®MLOpsã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã‚’ä½“é¨“ã—ã¾ã—ãŸï¼š\n",
        "\n",
        "| Section | å†…å®¹ |\n",
        "|---------|------|\n",
        "| 01 | ç’°å¢ƒæ§‹ç¯‰ |\n",
        "| 02 | Feature Store |\n",
        "| 03 | Model Training |\n",
        "| 04 | Experiment Tracking |\n",
        "| 05 | Model Registry |\n",
        "| 06 | Batch Inference |\n",
        "| 07 | Experiment Viewer (Streamlit) |\n",
        "\n",
        "ã“ã‚Œã‚‰ã‚’çµ„ã¿åˆã‚ã›ã‚‹ã“ã¨ã§ã€**æœ¬ç•ªé‹ç”¨å¯èƒ½ãªMLOpsãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³**ã‚’æ§‹ç¯‰ã§ãã¾ã™ï¼\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
