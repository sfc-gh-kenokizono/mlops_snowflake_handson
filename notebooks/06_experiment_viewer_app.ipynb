{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Section 6: Experiment Viewerï¼ˆStreamlitã‚¢ãƒ—ãƒªï¼‰\n",
        "\n",
        "## ğŸ¯ ã“ã®ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã®ç›®æ¨™\n",
        "- **Streamlit in Snowflake** ã§å®Ÿé¨“çµæœã‚’é–²è¦§ã§ãã‚‹ã‚¢ãƒ—ãƒªã‚’ä½œæˆ\n",
        "- éå»ã®å®Ÿé¨“ã®SHAPç”»åƒã‚„ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’ç°¡å˜ã«ç¢ºèªã§ãã‚‹ã‚ˆã†ã«ã™ã‚‹\n",
        "\n",
        "## ğŸ“‹ ãªãœå¿…è¦ï¼Ÿ\n",
        "- Snowsight UIã§ã¯ã‚¢ãƒ¼ãƒ†ã‚£ãƒ•ã‚¡ã‚¯ãƒˆç”»åƒã‚’ç›´æ¥ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ã§ããªã„\n",
        "- éå»ã®å®Ÿé¨“ã‚’æŒ¯ã‚Šè¿”ã‚‹éš›ã«ã€æ¯å›ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã§ã‚³ãƒ¼ãƒ‰ã‚’æ›¸ãã®ã¯é¢å€’\n",
        "- â†’ **ãƒ¯ãƒ³ã‚¯ãƒªãƒƒã‚¯ã§éå»ã®å®Ÿé¨“ã‚’å¯è¦–åŒ–**ã§ãã‚‹ã‚¢ãƒ—ãƒªãŒã‚ã‚‹ã¨ä¾¿åˆ©ï¼\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ’¡ å®Œæˆã‚¤ãƒ¡ãƒ¼ã‚¸\n",
        "\n",
        "```\n",
        "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
        "â”‚  ğŸ”¬ Experiment Viewer                                   â”‚\n",
        "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
        "â”‚  å®Ÿé¨“å: [CHURN_PREDICTION_EXPERIMENT â–¼]                â”‚\n",
        "â”‚  Run:    [Baseline â–¼]                                   â”‚\n",
        "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
        "â”‚  ğŸ“Š ãƒ¡ãƒˆãƒªã‚¯ã‚¹                                          â”‚\n",
        "â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”                 â”‚\n",
        "â”‚  â”‚F1: 0.78â”‚AUC:0.85â”‚Acc:0.82â”‚Time:2s â”‚                 â”‚\n",
        "â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”˜                 â”‚\n",
        "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
        "â”‚  ğŸ–¼ï¸ ã‚¢ãƒ¼ãƒ†ã‚£ãƒ•ã‚¡ã‚¯ãƒˆ                                    â”‚\n",
        "â”‚  [Confusion Matrix] [Feature Importance] [SHAP Plot]   â”‚\n",
        "â”‚                                                         â”‚\n",
        "â”‚         (é¸æŠã—ãŸç”»åƒãŒã“ã“ã«è¡¨ç¤º)                       â”‚\n",
        "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## 6.1 Streamlitã‚¢ãƒ—ãƒªã®ä½œæˆæ‰‹é †\n",
        "\n",
        "### Step 1: Streamlit Appä½œæˆç”»é¢ã‚’é–‹ã\n",
        "\n",
        "1. Snowsightå·¦ãƒ¡ãƒ‹ãƒ¥ãƒ¼ â†’ **Projects** â†’ **Streamlit**\n",
        "2. å³ä¸Šã® **+ Streamlit App** ã‚’ã‚¯ãƒªãƒƒã‚¯\n",
        "\n",
        "### Step 2: ã‚¢ãƒ—ãƒªè¨­å®š\n",
        "\n",
        "| é …ç›® | å€¤ |\n",
        "|------|---|\n",
        "| App name | `EXPERIMENT_VIEWER` |\n",
        "| App location (Database) | `MLOPS_HOL_DB` |\n",
        "| App location (Schema) | `FEATURE_STORE` |\n",
        "| App warehouse | `MLOPS_HOL_PYTHON_WH` |\n",
        "\n",
        "### Step 3: ã‚³ãƒ¼ãƒ‰ã‚’è²¼ã‚Šä»˜ã‘\n",
        "\n",
        "**2ã¤ã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³ãŒã‚ã‚Šã¾ã™ï¼š**\n",
        "\n",
        "| ãƒãƒ¼ã‚¸ãƒ§ãƒ³ | ç‰¹å¾´ | å¿…è¦ãªè¨­å®š |\n",
        "|-----------|------|-----------|\n",
        "| **A. æ£’ã‚°ãƒ©ãƒ•ç‰ˆ** | Altairã§å¯è¦–åŒ– | ãªã—ï¼ˆãã®ã¾ã¾å‹•ãï¼‰ |\n",
        "| **B. ç”»åƒè¡¨ç¤ºç‰ˆ** | Notebookã§ä¿å­˜ã—ãŸPNGç”»åƒã‚’è¡¨ç¤º | External Access Integration |\n",
        "\n",
        "> ğŸ’¡ **ãƒˆãƒ©ã‚¤ã‚¢ãƒ«ã‚¢ã‚«ã‚¦ãƒ³ãƒˆ**ã®å ´åˆã¯ **A. æ£’ã‚°ãƒ©ãƒ•ç‰ˆ** ã‚’ä½¿ç”¨ã—ã¦ãã ã•ã„\n",
        "> \n",
        "> ğŸ’¡ **ãƒ‡ãƒ¢ã‚¢ã‚«ã‚¦ãƒ³ãƒˆ**ç­‰ã§External AccessãŒä½¿ãˆã‚‹å ´åˆã¯ **B. ç”»åƒè¡¨ç¤ºç‰ˆ** ã‚‚åˆ©ç”¨å¯èƒ½\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "# ğŸ“‹ A. æ£’ã‚°ãƒ©ãƒ•ç‰ˆï¼ˆãƒ‘ãƒƒã‚±ãƒ¼ã‚¸è¿½åŠ ä¸è¦ãƒ»ãã®ã¾ã¾å‹•ãï¼‰\n",
        "# ============================================================\n",
        "\n",
        "streamlit_code = '''\n",
        "import streamlit as st\n",
        "from snowflake.snowpark.context import get_active_session\n",
        "import pandas as pd\n",
        "import json\n",
        "import altair as alt\n",
        "\n",
        "# ãƒšãƒ¼ã‚¸è¨­å®š\n",
        "st.set_page_config(\n",
        "    page_title=\"Experiment Viewer\",\n",
        "    page_icon=\"ğŸ”¬\",\n",
        "    layout=\"wide\"\n",
        ")\n",
        "\n",
        "# ã‚»ãƒƒã‚·ãƒ§ãƒ³å–å¾—\n",
        "session = get_active_session()\n",
        "\n",
        "st.title(\"ğŸ”¬ Experiment Viewer\")\n",
        "\n",
        "# ãƒ‡ãƒ¼ã‚¿å–å¾—\n",
        "df = session.table(\"MLOPS_HOL_DB.FEATURE_STORE.EXPERIMENT_RESULTS\").to_pandas()\n",
        "\n",
        "# ã‚¿ãƒ–ã§åˆ‡ã‚Šæ›¿ãˆ\n",
        "tab1, tab2 = st.tabs([\"ğŸ“Š æ¯”è¼ƒãƒ“ãƒ¥ãƒ¼\", \"ğŸ” è©³ç´°ãƒ“ãƒ¥ãƒ¼\"])\n",
        "\n",
        "# =====================================================\n",
        "# æ¯”è¼ƒãƒ“ãƒ¥ãƒ¼ï¼ˆå…¨Runæ¨ªä¸¦ã³ï¼‰\n",
        "# =====================================================\n",
        "with tab1:\n",
        "    st.header(\"ğŸ“Š å…¨Runã®æ¯”è¼ƒ\")\n",
        "    \n",
        "    # ãƒ¡ãƒˆãƒªã‚¯ã‚¹æ¯”è¼ƒãƒ†ãƒ¼ãƒ–ãƒ«ï¼ˆéå­¦ç¿’ãƒã‚§ãƒƒã‚¯ä»˜ãï¼‰\n",
        "    comparison_df = df[[\"RUN_NAME\", \"F1_SCORE\", \"TRAIN_F1_SCORE\", \"OVERFIT_GAP_F1\", \"ROC_AUC\", \"ACCURACY\"]].copy()\n",
        "    comparison_df.columns = [\"Run\", \"Test F1\", \"Train F1\", \"Gap\", \"ROC-AUC\", \"Accuracy\"]\n",
        "    st.dataframe(comparison_df, use_container_width=True, hide_index=True)\n",
        "    \n",
        "    st.caption(\"ğŸ’¡ Gap = Train F1 - Test F1ï¼ˆå¤§ãã„ã»ã©éå­¦ç¿’ã®å¯èƒ½æ€§ï¼‰\")\n",
        "    \n",
        "    st.divider()\n",
        "    \n",
        "    # ãƒ¡ãƒˆãƒªã‚¯ã‚¹æ£’ã‚°ãƒ©ãƒ•æ¯”è¼ƒ\n",
        "    st.subheader(\"ğŸ“ˆ ãƒ¡ãƒˆãƒªã‚¯ã‚¹æ¯”è¼ƒ\")\n",
        "    \n",
        "    metrics_data = []\n",
        "    for _, row in df.iterrows():\n",
        "        run_name = row[\"RUN_NAME\"].split(\"_\")[0]\n",
        "        metrics_data.append({\"Run\": run_name, \"Metric\": \"F1\", \"Value\": row[\"F1_SCORE\"]})\n",
        "        metrics_data.append({\"Run\": run_name, \"Metric\": \"ROC-AUC\", \"Value\": row[\"ROC_AUC\"]})\n",
        "        metrics_data.append({\"Run\": run_name, \"Metric\": \"Accuracy\", \"Value\": row[\"ACCURACY\"]})\n",
        "    \n",
        "    metrics_df = pd.DataFrame(metrics_data)\n",
        "    \n",
        "    chart = alt.Chart(metrics_df).mark_bar().encode(\n",
        "        x=alt.X(\"Run:N\"),\n",
        "        y=alt.Y(\"Value:Q\", scale=alt.Scale(domain=[0, 1])),\n",
        "        color=alt.Color(\"Run:N\"),\n",
        "        column=alt.Column(\"Metric:N\")\n",
        "    ).properties(width=150, height=300)\n",
        "    st.altair_chart(chart)\n",
        "    \n",
        "    st.divider()\n",
        "    \n",
        "    # ç‰¹å¾´é‡é‡è¦åº¦æ¯”è¼ƒ\n",
        "    st.subheader(\"ğŸ“ˆ ç‰¹å¾´é‡é‡è¦åº¦ æ¯”è¼ƒ\")\n",
        "    \n",
        "    imp_data = []\n",
        "    for _, row in df.iterrows():\n",
        "        run_name = row[\"RUN_NAME\"].split(\"_\")[0]\n",
        "        importance = json.loads(row[\"FEATURE_IMPORTANCE\"])\n",
        "        for feat, val in importance.items():\n",
        "            imp_data.append({\"Run\": run_name, \"Feature\": feat, \"Importance\": val})\n",
        "    \n",
        "    imp_df = pd.DataFrame(imp_data)\n",
        "    \n",
        "    imp_chart = alt.Chart(imp_df).mark_bar().encode(\n",
        "        x=alt.X(\"Importance:Q\"),\n",
        "        y=alt.Y(\"Feature:N\", sort=\"-x\"),\n",
        "        color=alt.Color(\"Run:N\"),\n",
        "        row=alt.Row(\"Run:N\")\n",
        "    ).properties(height=150)\n",
        "    st.altair_chart(imp_chart, use_container_width=True)\n",
        "\n",
        "# =====================================================\n",
        "# è©³ç´°ãƒ“ãƒ¥ãƒ¼ï¼ˆ1Runè©³ç´°ï¼‰\n",
        "# =====================================================\n",
        "with tab2:\n",
        "    st.header(\"ğŸ” Runè©³ç´°\")\n",
        "    \n",
        "    selected_run = st.selectbox(\"Runå\", df[\"RUN_NAME\"].tolist())\n",
        "    run_data = df[df[\"RUN_NAME\"] == selected_run].iloc[0]\n",
        "    \n",
        "    col1, col2, col3, col4, col5 = st.columns(5)\n",
        "    col1.metric(\"F1 Score\", f\"{run_data['F1_SCORE']:.4f}\")\n",
        "    col2.metric(\"ROC-AUC\", f\"{run_data['ROC_AUC']:.4f}\")\n",
        "    col3.metric(\"Accuracy\", f\"{run_data['ACCURACY']:.4f}\")\n",
        "    col4.metric(\"Precision\", f\"{run_data['PRECISION']:.4f}\")\n",
        "    col5.metric(\"Recall\", f\"{run_data['RECALL']:.4f}\")\n",
        "    \n",
        "    st.divider()\n",
        "    \n",
        "    col_left, col_right = st.columns(2)\n",
        "    \n",
        "    with col_left:\n",
        "        st.subheader(\"âš™ï¸ ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿\")\n",
        "        st.json(json.loads(run_data['PARAMS']))\n",
        "    \n",
        "    with col_right:\n",
        "        st.subheader(\"ğŸ“ˆ ç‰¹å¾´é‡é‡è¦åº¦\")\n",
        "        importance = json.loads(run_data['FEATURE_IMPORTANCE'])\n",
        "        imp_df = pd.DataFrame({\n",
        "            \"Feature\": list(importance.keys()),\n",
        "            \"Importance\": list(importance.values())\n",
        "        }).sort_values(\"Importance\", ascending=False)\n",
        "        \n",
        "        chart = alt.Chart(imp_df).mark_bar(color=\"steelblue\").encode(\n",
        "            x=alt.X(\"Importance:Q\"),\n",
        "            y=alt.Y(\"Feature:N\", sort=\"-x\")\n",
        "        ).properties(height=250)\n",
        "        st.altair_chart(chart, use_container_width=True)\n",
        "    \n",
        "    st.divider()\n",
        "    \n",
        "    # SHAPå€¤\n",
        "    st.subheader(\"ğŸ” SHAPå€¤ï¼ˆå¹³å‡çµ¶å¯¾å€¤ï¼‰\")\n",
        "    shap_imp = json.loads(run_data['SHAP_IMPORTANCE'])\n",
        "    shap_df = pd.DataFrame({\n",
        "        \"Feature\": list(shap_imp.keys()),\n",
        "        \"SHAP\": list(shap_imp.values())\n",
        "    }).sort_values(\"SHAP\", ascending=False)\n",
        "    \n",
        "    shap_chart = alt.Chart(shap_df).mark_bar(color=\"coral\").encode(\n",
        "        x=alt.X(\"SHAP:Q\"),\n",
        "        y=alt.Y(\"Feature:N\", sort=\"-x\")\n",
        "    ).properties(height=250)\n",
        "    st.altair_chart(shap_chart, use_container_width=True)\n",
        "    \n",
        "    st.divider()\n",
        "    \n",
        "    with st.expander(\"ğŸ“‹ ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆæƒ…å ±\"):\n",
        "        st.json(json.loads(run_data['DATASET_INFO']))\n",
        "\n",
        "st.caption(\"ğŸ”¬ MLOps Hands-on - Experiment Viewer\")\n",
        "'''\n",
        "\n",
        "print(\"=\" * 70)\n",
        "print(\"ğŸ“‹ A. æ£’ã‚°ãƒ©ãƒ•ç‰ˆï¼ˆãƒ‘ãƒƒã‚±ãƒ¼ã‚¸è¿½åŠ ä¸è¦ï¼‰\")\n",
        "print(\"=\" * 70)\n",
        "print(streamlit_code)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## 6.1.2 B. ç”»åƒè¡¨ç¤ºç‰ˆï¼ˆExternal Accesså¿…è¦ï¼‰\n",
        "\n",
        "Notebookã§ä¿å­˜ã—ãŸSHAP Summary Plotç­‰ã®PNGç”»åƒã‚’è¡¨ç¤ºã§ãã¾ã™ã€‚\n",
        "\n",
        "### äº‹å‰æº–å‚™ï¼ˆExternal Access Integrationï¼‰\n",
        "\n",
        "ä»¥ä¸‹ã®SQLã‚’Worksheetã§å®Ÿè¡Œã—ã¦ãã ã•ã„ï¼š\n",
        "\n",
        "```sql\n",
        "USE ROLE ACCOUNTADMIN;\n",
        "\n",
        "CREATE OR REPLACE NETWORK RULE pypi_network_rule\n",
        "  MODE = EGRESS\n",
        "  TYPE = HOST_PORT\n",
        "  VALUE_LIST = ('pypi.org', 'files.pythonhosted.org');\n",
        "\n",
        "CREATE OR REPLACE EXTERNAL ACCESS INTEGRATION pypi_access_integration\n",
        "  ALLOWED_NETWORK_RULES = (pypi_network_rule)\n",
        "  ENABLED = TRUE;\n",
        "\n",
        "ALTER STREAMLIT MLOPS_HOL_DB.FEATURE_STORE.EXPERIMENT_VIEWER \n",
        "  SET EXTERNAL_ACCESS_INTEGRATIONS = (pypi_access_integration);\n",
        "```\n",
        "\n",
        "### pyproject.toml ã®ç·¨é›†\n",
        "\n",
        "```toml\n",
        "[project]\n",
        "name = \"streamlit-app\"\n",
        "requires-python = \">= 3.11\"\n",
        "version = \"0.0.1\"\n",
        "dependencies = [\n",
        "    \"streamlit[snowflake]\",\n",
        "    \"snowflake-ml-python\"\n",
        "]\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "# ğŸ“‹ B. ç”»åƒè¡¨ç¤ºç‰ˆï¼ˆExternal Access Integrationå¿…è¦ï¼‰\n",
        "# ============================================================\n",
        "\n",
        "streamlit_code_with_images = '''\n",
        "import streamlit as st\n",
        "from snowflake.snowpark.context import get_active_session\n",
        "from snowflake.ml.experiment import ExperimentTracking\n",
        "import pandas as pd\n",
        "import json\n",
        "import altair as alt\n",
        "import os\n",
        "\n",
        "st.set_page_config(page_title=\"Experiment Viewer\", page_icon=\"ğŸ”¬\", layout=\"wide\")\n",
        "\n",
        "session = get_active_session()\n",
        "\n",
        "st.title(\"ğŸ”¬ Experiment Viewer\")\n",
        "\n",
        "# ãƒ‡ãƒ¼ã‚¿å–å¾—\n",
        "df = session.table(\"MLOPS_HOL_DB.FEATURE_STORE.EXPERIMENT_RESULTS\").to_pandas()\n",
        "\n",
        "# ã‚¿ãƒ–ã§åˆ‡ã‚Šæ›¿ãˆ\n",
        "tab1, tab2, tab3 = st.tabs([\"ğŸ“Š æ¯”è¼ƒãƒ“ãƒ¥ãƒ¼\", \"ğŸ” è©³ç´°ãƒ“ãƒ¥ãƒ¼\", \"ğŸ–¼ï¸ ç”»åƒãƒ“ãƒ¥ãƒ¼\"])\n",
        "\n",
        "# =====================================================\n",
        "# æ¯”è¼ƒãƒ“ãƒ¥ãƒ¼\n",
        "# =====================================================\n",
        "with tab1:\n",
        "    st.header(\"ğŸ“Š å…¨Runã®æ¯”è¼ƒ\")\n",
        "    \n",
        "    comparison_df = df[[\"RUN_NAME\", \"F1_SCORE\", \"TRAIN_F1_SCORE\", \"OVERFIT_GAP_F1\", \"ROC_AUC\", \"ACCURACY\"]].copy()\n",
        "    comparison_df.columns = [\"Run\", \"Test F1\", \"Train F1\", \"Gap\", \"ROC-AUC\", \"Accuracy\"]\n",
        "    st.dataframe(comparison_df, use_container_width=True, hide_index=True)\n",
        "    \n",
        "    st.caption(\"ğŸ’¡ Gap = Train F1 - Test F1ï¼ˆå¤§ãã„ã»ã©éå­¦ç¿’ã®å¯èƒ½æ€§ï¼‰\")\n",
        "    \n",
        "    st.divider()\n",
        "    \n",
        "    st.subheader(\"ğŸ“ˆ ãƒ¡ãƒˆãƒªã‚¯ã‚¹æ¯”è¼ƒ\")\n",
        "    metrics_data = []\n",
        "    for _, row in df.iterrows():\n",
        "        run_name = row[\"RUN_NAME\"].split(\"_\")[0]\n",
        "        metrics_data.append({\"Run\": run_name, \"Metric\": \"F1\", \"Value\": row[\"F1_SCORE\"]})\n",
        "        metrics_data.append({\"Run\": run_name, \"Metric\": \"ROC-AUC\", \"Value\": row[\"ROC_AUC\"]})\n",
        "        metrics_data.append({\"Run\": run_name, \"Metric\": \"Accuracy\", \"Value\": row[\"ACCURACY\"]})\n",
        "    \n",
        "    metrics_df = pd.DataFrame(metrics_data)\n",
        "    chart = alt.Chart(metrics_df).mark_bar().encode(\n",
        "        x=alt.X(\"Run:N\"),\n",
        "        y=alt.Y(\"Value:Q\", scale=alt.Scale(domain=[0, 1])),\n",
        "        color=alt.Color(\"Run:N\"),\n",
        "        column=alt.Column(\"Metric:N\")\n",
        "    ).properties(width=150, height=300)\n",
        "    st.altair_chart(chart)\n",
        "\n",
        "# =====================================================\n",
        "# è©³ç´°ãƒ“ãƒ¥ãƒ¼\n",
        "# =====================================================\n",
        "with tab2:\n",
        "    st.header(\"ğŸ” Runè©³ç´°\")\n",
        "    \n",
        "    selected_run = st.selectbox(\"Runå\", df[\"RUN_NAME\"].tolist(), key=\"detail_run\")\n",
        "    run_data = df[df[\"RUN_NAME\"] == selected_run].iloc[0]\n",
        "    \n",
        "    col1, col2, col3, col4, col5 = st.columns(5)\n",
        "    col1.metric(\"F1 Score\", f\"{run_data['F1_SCORE']:.4f}\")\n",
        "    col2.metric(\"ROC-AUC\", f\"{run_data['ROC_AUC']:.4f}\")\n",
        "    col3.metric(\"Accuracy\", f\"{run_data['ACCURACY']:.4f}\")\n",
        "    col4.metric(\"Precision\", f\"{run_data['PRECISION']:.4f}\")\n",
        "    col5.metric(\"Recall\", f\"{run_data['RECALL']:.4f}\")\n",
        "    \n",
        "    st.divider()\n",
        "    \n",
        "    col_left, col_right = st.columns(2)\n",
        "    with col_left:\n",
        "        st.subheader(\"âš™ï¸ ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿\")\n",
        "        st.json(json.loads(run_data['PARAMS']))\n",
        "    \n",
        "    with col_right:\n",
        "        st.subheader(\"ğŸ“ˆ ç‰¹å¾´é‡é‡è¦åº¦\")\n",
        "        importance = json.loads(run_data['FEATURE_IMPORTANCE'])\n",
        "        imp_df = pd.DataFrame({\n",
        "            \"Feature\": list(importance.keys()),\n",
        "            \"Importance\": list(importance.values())\n",
        "        }).sort_values(\"Importance\", ascending=False)\n",
        "        chart = alt.Chart(imp_df).mark_bar(color=\"steelblue\").encode(\n",
        "            x=alt.X(\"Importance:Q\"),\n",
        "            y=alt.Y(\"Feature:N\", sort=\"-x\")\n",
        "        ).properties(height=250)\n",
        "        st.altair_chart(chart, use_container_width=True)\n",
        "\n",
        "# =====================================================\n",
        "# ç”»åƒãƒ“ãƒ¥ãƒ¼ï¼ˆã‚¢ãƒ¼ãƒ†ã‚£ãƒ•ã‚¡ã‚¯ãƒˆï¼‰\n",
        "# =====================================================\n",
        "with tab3:\n",
        "    st.header(\"ğŸ–¼ï¸ ã‚¢ãƒ¼ãƒ†ã‚£ãƒ•ã‚¡ã‚¯ãƒˆç”»åƒ\")\n",
        "    \n",
        "    exp = ExperimentTracking(session=session)\n",
        "    exp.set_experiment(\"CHURN_PREDICTION_EXPERIMENT\")\n",
        "    \n",
        "    selected_run_img = st.selectbox(\"Runå\", df[\"RUN_NAME\"].tolist(), key=\"image_run\")\n",
        "    display_name = selected_run_img.split(\"_\")[0]\n",
        "    \n",
        "    image_type = st.radio(\n",
        "        \"è¡¨ç¤ºã™ã‚‹ç”»åƒ\",\n",
        "        [\"Confusion Matrix\", \"Feature Importance\", \"SHAP Summary Plot\"],\n",
        "        horizontal=True\n",
        "    )\n",
        "    \n",
        "    artifact_map = {\n",
        "        \"Confusion Matrix\": f\"confusion_matrix_{display_name}.png\",\n",
        "        \"Feature Importance\": f\"feature_importance_{display_name}.png\",\n",
        "        \"SHAP Summary Plot\": f\"shap_summary_{display_name}.png\"\n",
        "    }\n",
        "    \n",
        "    artifact_name = artifact_map[image_type]\n",
        "    download_path = \"/tmp/viewer/\"\n",
        "    os.makedirs(download_path, exist_ok=True)\n",
        "    \n",
        "    if st.button(f\"ğŸ“¥ {image_type} ã‚’è¡¨ç¤º\", type=\"primary\"):\n",
        "        with st.spinner(\"ç”»åƒã‚’å–å¾—ä¸­...\"):\n",
        "            try:\n",
        "                exp.download_artifacts(\n",
        "                    run_name=selected_run_img,\n",
        "                    artifact_path=artifact_name,\n",
        "                    target_path=download_path\n",
        "                )\n",
        "                image_path = f\"{download_path}{artifact_name}\"\n",
        "                if os.path.exists(image_path):\n",
        "                    st.image(image_path, caption=f\"{image_type} - {display_name}\")\n",
        "                    st.success(\"âœ… ç”»åƒã‚’è¡¨ç¤ºã—ã¾ã—ãŸ\")\n",
        "                else:\n",
        "                    st.warning(\"ç”»åƒãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“\")\n",
        "            except Exception as e:\n",
        "                st.error(f\"ã‚¨ãƒ©ãƒ¼: {e}\")\n",
        "\n",
        "st.caption(\"ğŸ”¬ MLOps Hands-on - Experiment Viewer\")\n",
        "'''\n",
        "\n",
        "print(\"=\" * 70)\n",
        "print(\"ğŸ“‹ B. ç”»åƒè¡¨ç¤ºç‰ˆï¼ˆExternal Access Integrationå¿…è¦ï¼‰\")\n",
        "print(\"=\" * 70)\n",
        "print(streamlit_code_with_images)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## 6.2 ã‚¢ãƒ—ãƒªã®æ©Ÿèƒ½è§£èª¬\n",
        "\n",
        "### ğŸ“Š ãƒ¡ãƒˆãƒªã‚¯ã‚¹è¡¨ç¤º\n",
        "```python\n",
        "# EXPERIMENT_RESULTSãƒ†ãƒ¼ãƒ–ãƒ«ã‹ã‚‰å–å¾—\n",
        "st.metric(\"F1 Score\", f\"{run_data['F1_SCORE']:.4f}\")\n",
        "```\n",
        "- Section 4ã§ä¿å­˜ã—ãŸãƒ†ãƒ¼ãƒ–ãƒ«ã‹ã‚‰ç›´æ¥èª­ã¿è¾¼ã¿\n",
        "- ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã§æœ€æ–°ãƒ‡ãƒ¼ã‚¿ã‚’è¡¨ç¤º\n",
        "\n",
        "### ğŸ“ˆ ç‰¹å¾´é‡é‡è¦åº¦ã‚°ãƒ©ãƒ•\n",
        "```python\n",
        "# JSONã‚’ãƒ‘ãƒ¼ã‚¹ã—ã¦æ£’ã‚°ãƒ©ãƒ•åŒ–\n",
        "importance = json.loads(run_data['FEATURE_IMPORTANCE'])\n",
        "```\n",
        "- Altairã§å‹•çš„ãªã‚°ãƒ©ãƒ•ã‚’ç”Ÿæˆ\n",
        "- é‡è¦åº¦é †ã«ã‚½ãƒ¼ãƒˆã—ã¦è¡¨ç¤º\n",
        "\n",
        "### ğŸ–¼ï¸ ã‚¢ãƒ¼ãƒ†ã‚£ãƒ•ã‚¡ã‚¯ãƒˆç”»åƒ\n",
        "```python\n",
        "# Experiment Trackingã‹ã‚‰ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰\n",
        "exp.download_artifacts(\n",
        "    run_name=selected_run,\n",
        "    artifact_path=artifact_name,\n",
        "    target_path=download_path\n",
        ")\n",
        "st.image(image_path)\n",
        "```\n",
        "- ãƒœã‚¿ãƒ³ã‚¯ãƒªãƒƒã‚¯ã§ã‚ªãƒ³ãƒ‡ãƒãƒ³ãƒ‰ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰\n",
        "- å¿…è¦ãªç”»åƒã ã‘å–å¾—ã™ã‚‹ã®ã§è»½é‡\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## âœ… Section 6 å®Œäº†ï¼\n",
        "\n",
        "### å­¦ã‚“ã ã“ã¨\n",
        "- **Streamlit in Snowflake** ã§ã‚¢ãƒ—ãƒªã‚’ä½œæˆ\n",
        "- Experiment Trackingã®ãƒ‡ãƒ¼ã‚¿ã‚’å¯è¦–åŒ–\n",
        "- ã‚¢ãƒ¼ãƒ†ã‚£ãƒ•ã‚¡ã‚¯ãƒˆï¼ˆç”»åƒï¼‰ã‚’ã‚¢ãƒ—ãƒªå†…ã§è¡¨ç¤º\n",
        "\n",
        "### ä½œæˆã—ãŸã‚‚ã®\n",
        "- Streamlit App: `EXPERIMENT_VIEWER`\n",
        "  - å®Ÿé¨“ãƒ»Runé¸æŠæ©Ÿèƒ½\n",
        "  - ãƒ¡ãƒˆãƒªã‚¯ã‚¹è¡¨ç¤ºï¼ˆF1, AUC, Accuracyç­‰ï¼‰\n",
        "  - ç‰¹å¾´é‡é‡è¦åº¦ã‚°ãƒ©ãƒ•\n",
        "  - SHAPå€¤ã‚°ãƒ©ãƒ•\n",
        "  - ã‚¢ãƒ¼ãƒ†ã‚£ãƒ•ã‚¡ã‚¯ãƒˆç”»åƒè¡¨ç¤º\n",
        "\n",
        "### ğŸ’¡ æ´»ç”¨ã‚·ãƒ¼ãƒ³\n",
        "- **å®Ÿé¨“ãƒ¬ãƒ“ãƒ¥ãƒ¼**: éå»ã®å®Ÿé¨“çµæœã‚’ãƒãƒ¼ãƒ ã§å…±æœ‰\n",
        "- **ãƒ¢ãƒ‡ãƒ«é¸å®š**: è¤‡æ•°ãƒ¢ãƒ‡ãƒ«ã®æ¯”è¼ƒæ¤œè¨\n",
        "- **ç›£æŸ»å¯¾å¿œ**: ãƒ¢ãƒ‡ãƒ«ã®èª¬æ˜è²¬ä»»ã‚’æœãŸã™\n",
        "- **ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ**: ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚·ãƒ§ãƒƒãƒˆã§ãƒ¬ãƒãƒ¼ãƒˆä½œæˆ\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ‰ ãƒãƒ³ã‚ºã‚ªãƒ³å®Œäº†ï¼\n",
        "\n",
        "ãŠç–²ã‚Œã•ã¾ã§ã—ãŸï¼ä»¥ä¸‹ã®MLOpsã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã‚’ä½“é¨“ã—ã¾ã—ãŸï¼š\n",
        "\n",
        "| Section | å†…å®¹ |\n",
        "|---------|------|\n",
        "| 01 | ç’°å¢ƒæ§‹ç¯‰ãƒ»ãƒ‡ãƒ¼ã‚¿æ¢ç´¢ |\n",
        "| 02 | Feature Store |\n",
        "| 03 | Model Training |\n",
        "| 04 | Experiment Tracking |\n",
        "| 05 | Model Registry & æ¨è«– |\n",
        "| 06 | Experiment Viewer (Streamlit) |\n",
        "\n",
        "ã“ã‚Œã‚‰ã‚’çµ„ã¿åˆã‚ã›ã‚‹ã“ã¨ã§ã€**æœ¬ç•ªé‹ç”¨å¯èƒ½ãªMLOpsãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³**ã‚’æ§‹ç¯‰ã§ãã¾ã™ï¼\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
